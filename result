teacher_force 0.01
Training Loss 0.8851650156052465
Training Loss 0.9779541172932104
Training Loss 0.9037385963798608
Training Loss 0.8073888607752884
Training Loss 0.9723014678914377
Training Loss 0.8924358768550228
Training Loss 0.8853359351933865
Training Loss 0.883128108680862
Training Loss 0.8476309578417999
Training Loss 0.8505569407919278
Training Loss 0.9545007631099424
Training Loss 0.8376738094942369
Training loss  0.19181302687290214
Training Loss 0.7965537137763444
Training Loss 0.9124770662341023
Training Loss 0.9514319348563097
Training loss  0.05171307196537289
Training Loss 0.8980768234735885
Training Loss 0.9371774985736896
Training loss  0.010265719506048487
Training Loss 0.9653359142022863
Training loss  0.009797404198673254
Training Loss 0.8518412163917054
Training loss  0.004387441867059971
Training Loss 0.6167602947597682
Training loss  0.11427633112127134
Training loss  0.11404264797025099
Training loss  0.2847147663356888
Training Loss 0.9225650611422596
Training Loss 0.845996230183755
Training Loss 0.9394429783582485
Training Loss 0.8368714877749067
Training Loss 0.7440221069981812
Training loss  0.07138278030247269
Training loss  0.06495115833044385
Training Loss 0.8293807204263483
Training Loss 0.7905336534049192
Training Loss 0.7678932627460129
Training Loss 0.791910251795364
Training Loss 0.8200392132788806
Training Loss 0.7773320700819354
Training Loss 0.925844797411719
Training loss  0.10558323678607207
Training Loss 0.9108068052338614
Training loss  0.026006349860679956
Training loss  0.10343694276478321
Training loss  0.01918696979235479
Training Loss 0.8590689978239845
Training Loss 0.9000988740187424
Training Loss 0.7806005045572917
Training Loss 0.8594083745428857
Training Loss 0.8329188910756751
Training Loss 0.8044459079722521
Training loss  0.05025583226395325
Training Loss 0.9373538477891157
Training Loss 0.8828498928650935
Training Loss 0.9991181537573712
Training loss  0.009700510571011955
Training Loss 0.9944416356986036
Training Loss 0.7773892891839378
Training Loss 0.9815208631805158
Training Loss 0.7825337751276611
Training loss  0.1104609137136332
Training Loss 0.97392578125
Training Loss 0.7964747433254409
Training loss  0.044417922561233114
Training Loss 0.9061504297810069
Training Loss 0.8934895338620821
Training loss  0.06434572272906514
Training loss  0.2210254728682548
Training Loss 0.8212951366800961
Training Loss 0.9402132709283579
Training Loss 0.8937018669877614
Training Loss 0.9525582887444227
Training loss  0.08046480455340643
Training Loss 0.6652009686631677
Training Loss 0.9662699021318175
Training Loss 0.8289543098503059
Loss and Error 0.5721033170971375 22.102808845495282
saving as ./model10//000_22.1028.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.9159899725430254
Training Loss 0.9160928449644993
Training Loss 0.9844927845509232
Training Loss 0.836938844538219
Training Loss 0.9147639570635159
Training loss  0.16535478136934478
Training Loss 0.7723642010392985
Training loss  0.29256033791998237
Training Loss 0.8522707213465743
Training Loss 0.8468271817197058
Training loss  0.02318406893325009
Training Loss 0.7867813295981599
Training Loss 0.8593988893258625
Training Loss 0.7469962326880705
Training Loss 0.654626070107535
Training loss  0.01513671875
Training Loss 0.9423478831811902
Training Loss 0.9192530650647842
Training Loss 0.8212516394844891
Training Loss 0.7813253084912267
Training loss  0.043341413332629086
Training loss  0.16382540258408151
Training Loss 0.9932112452071933
Training Loss 0.9512270195539607
Training Loss 0.9723171441940108
Training Loss 0.8772321319817976
Training loss  0.01734788980589408
Training Loss 0.7272240761598926
Training Loss 0.9023594200428938
Training loss  0.18794406394288066
Training loss  0.14133387493780614
Training Loss 0.9593455772878519
Training Loss 0.822519099279226
Training Loss 0.9894834925862477
Training Loss 0.9272108576780866
Training Loss 0.8613944549773361
Training loss  0.049367661459941425
Training Loss 0.8881867860791234
Training Loss 0.7573897104414683
Training Loss 0.9310681632395541
Training Loss 0.7587376755731716
Training Loss 0.92292656379541
Training Loss 0.8034401113675179
Training Loss 0.9984608134569039
Training Loss 0.9683220922300761
Training Loss 0.9256665110240525
Training loss  0.23991406582069996
Training loss  0.02760717306926752
Training Loss 0.6005580983263381
Training Loss 0.840298883641707
Training Loss 0.9374813287586906
Training Loss 0.7983107438588783
Training Loss 0.8945916707083683
Training Loss 0.6765073469883419
Training Loss 0.8217345388814965
Training Loss 0.7937828258603168
Training loss  0.05907928484865299
Training loss  0.07471665876988709
Training Loss 0.9845020910067526
Training Loss 0.7218443027362298
Training loss  0.0933335000269706
Training Loss 0.7124311543421725
Training Loss 0.8088984281654132
Training Loss 0.8524659213362069
Training Loss 0.7694779172130515
Training Loss 0.9803604950775971
Training Loss 0.9454613490694365
Training Loss 0.9927263810386888
Training Loss 0.8467385907685155
Training Loss 0.9080818999522143
Training loss  0.20725303442663123
Training loss  0.12476337349608291
Training Loss 0.9954854539397746
Training Loss 0.9684069248321175
Training Loss 0.7052099324385943
Training Loss 0.9453550919637541
Training Loss 0.8486051427279027
Training Loss 0.9866683317149686
Loss and Error 0.5858144801486933 20.63918539837517
saving as ./model10//001_20.6392.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8541829994801449
Training Loss 0.9999020134582863
Training Loss 0.819955723671195
Training Loss 0.8766768496260684
Training loss  0.051063471611243694
Training Loss 0.7547699502595155
Training Loss 0.5410927713392994
Training Loss 0.9790558078793052
Training loss  0.0361826943709711
Training loss  0.023072800581971364
Training loss  0.08057030248111996
Training Loss 0.8538252562939753
Training Loss 0.7400949342132042
Training loss  0.029055271079050815
Training Loss 0.9109503892124836
Training loss  0.017738016601831497
Training Loss 0.7914260005287397
Training Loss 0.8238795792502279
Training loss  0.00936979223427059
Training Loss 0.6534660139167274
Training Loss 0.48328093998015875
Training Loss 0.7791305087979059
Training Loss 0.9304075810273295
Training Loss 0.774474898064503
Training Loss 0.760883726088196
Training Loss 0.8484142616855525
Training Loss 0.8710358926166966
Training Loss 0.9013222200658891
Training Loss 0.7635556279582215
Training Loss 0.9064189458664209
Training Loss 0.8381409502191458
Training Loss 0.8700721958705357
Training Loss 0.951834627841779
Training Loss 0.6060692109128376
Training Loss 0.7449406982506971
Training loss  0.12093639925036137
Training Loss 0.75444486440008
Training Loss 0.9821291546689513
Training loss  0.09223142326819977
Training Loss 0.8598039245605469
Training Loss 0.7614451729043661
Training Loss 0.883569871126491
Training Loss 0.9409797144435754
Training Loss 0.8291943661760911
Training Loss 0.96260632527978
Training loss  0.13820655580048413
Training Loss 0.8640840957103981
Training Loss 0.8306208512614004
Training Loss 0.9501111538119572
Training Loss 0.6839961413721105
Training Loss 0.8311840624069664
Training Loss 0.765292947729282
Training loss  0.026334114764429817
Training Loss 0.8640553374268692
Training Loss 0.9510000344703485
Training Loss 0.9536193094135802
Training Loss 0.8290127759461009
Training Loss 0.9449888530530428
Training loss  0.026091162593858908
Training Loss 0.9260428853465926
Training Loss 0.8908363490382357
Training loss  0.1401998795087065
Training Loss 0.7031605273309761
Training Loss 0.8856258182735234
Training Loss 0.7362415068190737
Training Loss 0.7162946270532428
Training Loss 0.9205008171110626
Training Loss 0.8397769278344585
Training Loss 0.8919454540726701
Training loss  0.015432797669242326
Training Loss 0.6594789781196764
Training Loss 0.8871256510416666
Training loss  0.1352342163266249
Training Loss 0.07577815492813031
Training loss  0.001255624702002578
Training Loss 0.8852928272192029
Training Loss 0.8515289094392576
Training loss  0.01655437160996054
Loss and Error 0.5226701338294044 24.07100440817516
saving as ./model10//002_24.0710.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.9462253220394267
Training loss  0.2212636748705905
Training Loss 0.6864928900904204
Training Loss 0.9051372943146859
Training Loss 0.7445740407124323
Training Loss 0.6284714215303682
Training Loss 0.8133657326796188
Training Loss 0.8134280669161464
Training Loss 0.70720703125
Training Loss 0.8052741166509707
Training Loss 0.8566871084371248
Training Loss 0.5966806507255311
Training Loss 0.9305658826239946
Training loss  0.031916194554952426
Training loss  0.030703575903705982
Training Loss 0.899500071414321
Training Loss 0.9514418210014725
Training Loss 0.9609770387285521
Training Loss 0.7250113651670259
Training Loss 0.8862331163937642
Training Loss 0.9064397918039689
Training Loss 0.7695372651678473
Training Loss 0.7064291250957284
Training Loss 0.9448029831350607
Training Loss 0.7466938935921167
Training Loss 0.7129886898535565
Training Loss 0.7280119906443161
Training Loss 0.6631260790036172
Training loss  0.00665232760847112
Training Loss 0.81172991170161
Training Loss 0.8651751452255767
Training loss  0.053355069119236376
Training Loss 0.839444719671913
Training Loss 0.8370440584711867
Training Loss 0.8005390204562133
Training Loss 0.9265138172833531
Training Loss 0.7368463724637941
Training loss  0.09025481058328322
Training Loss 0.9140714028452046
Training Loss 0.991148514771553
Training Loss 0.9082945357921511
Training Loss 0.6787931157836385
Training loss  0.031066619598113743
Training Loss 0.7708929829842444
Training Loss 0.8635332210230527
Training Loss 0.8228709162940091
Training Loss 0.9309876259925224
Training Loss 0.7761789852376639
Training Loss 0.839300105376647
Training loss  0.045466791755406355
Training Loss 0.8996995286149282
Training loss  0.09335831207483003
Training Loss 0.6563142647458975
Training loss  0.04120305736483165
Training loss  0.19023189928354922
Training loss  0.04394188180649583
Training Loss 0.9301574590009586
Training Loss 0.718387703853863
Training Loss 0.7499361141451438
Training Loss 0.8520591358721483
Training Loss 0.7754889194244102
Training Loss 0.700954295797579
Training Loss 0.06199172251193732
Training Loss 0.9973651607608259
Training Loss 0.7930281045887437
Training Loss 0.9163712674990071
Training loss  0.047496322312822414
Training Loss 0.7428596611829683
Training Loss 0.7023023062749834
Training Loss 0.7917620645185407
Training Loss 0.9812733502395891
Training loss  0.12149161911554929
Training Loss 0.6681417745870871
Training Loss 0.859338551386297
Training Loss 0.9032464454553245
Training Loss 0.8734225630069525
Training loss  0.013012628587154573
Training loss  0.03743530273437501
Loss and Error 0.5827799910995912 22.038143466064337
saving as ./model10//003_22.0381.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8717317481489547
Training Loss 0.7598454645753817
Training Loss 0.8748395670251891
Training Loss 0.9955720939833429
Training Loss 0.954199354007964
Training Loss 0.933785788779557
Training loss  0.0062677658395309255
Training Loss 0.7856059517302473
Training Loss 0.851566585351824
Training Loss 0.6889530194912294
Training Loss 0.6507805583834986
Training Loss 0.887232755649078
Training Loss 0.9308562832287336
Training Loss 0.7530763643281954
Training Loss 0.7179240473994503
Training Loss 0.9630295729585524
Training Loss 0.929922022343881
Training Loss 0.711607591340902
Training loss  0.15548923168931417
Training Loss 0.689195524657137
Training Loss 0.8515376535607383
Training Loss 0.8259153585829493
Training Loss 0.9535224294159296
Training Loss 0.7235376038136428
Training Loss 0.7004799773405649
Training Loss 0.8276155065317623
Training Loss 0.8016813917503463
Training loss  0.0012933110057351538
Training Loss 0.7776345274671538
Training Loss 0.908418633850706
Training Loss 0.8618909206343052
Training loss  0.22035549072609006
Training Loss 0.7404983675015342
Training loss  0.0012410424701962963
Training Loss 0.7865749149837071
Training Loss 0.8710965614544429
Training Loss 0.7341814671127562
Training Loss 0.719382466577019
Training Loss 0.9571881466735341
Training Loss 0.7933898569313758
Training Loss 0.6659506363686779
Training Loss 0.9237876996904375
Training Loss 0.895044596731801
Training Loss 0.8085648672921317
Training Loss 0.8513394083681934
Training Loss 0.8924788464100633
Training Loss 0.7516198129236995
Training Loss 0.552522138681056
Training loss  0.24101197195352664
Training Loss 0.9691818932652845
Training Loss 0.9234595262022081
Training Loss 0.880073559987762
Training Loss 0.7924723211998682
Training Loss 0.9644978300916092
Training loss  0.072930073295989
Training Loss 0.7100959474025519
Training Loss 0.8845680150480196
Training Loss 0.9136049203907193
Training Loss 0.9166074725324207
Training Loss 0.9089993287054515
Training Loss 0.8413214503420526
Training Loss 0.9367848911443906
Training Loss 0.9631872838254983
Training Loss 0.9324723176385166
Training Loss 0.9274535602840087
Training Loss 0.6079237244192478
Training Loss 0.8409486478173812
Training Loss 0.7417081841568665
Training Loss 0.8652604102551702
Training Loss 0.9963476167815387
Training Loss 0.7945994374860158
Training Loss 0.754955598417569
Training Loss 0.8935984961887926
Training Loss 0.5740193063576076
Training Loss 0.74991347095599
Training Loss 0.9750744119963441
Training Loss 0.80290442462802
Training Loss 0.7525378399990795
Loss and Error 0.6213988501441594 19.696528106670552
saving as ./model10//004_19.6965.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7304548052367091
Training Loss 0.7168811317581137
Training Loss 0.8508317750831067
Training Loss 0.9248224239100941
Training Loss 0.8447493818751708
Training Loss 0.8502302039387547
Training Loss 0.8552933160254446
Training Loss 0.8415837261341982
Training Loss 0.7789551652402988
Training Loss 0.8286388325241377
Training Loss 0.9902909035728068
Training Loss 0.907628665377993
Training Loss 0.9403951160459285
Training Loss 0.8732075271211139
Training Loss 0.7001556185754081
Training Loss 0.8848459750791139
Training Loss 0.7247045873834816
Training Loss 0.8621632394371915
Training Loss 0.8210026003279776
Training Loss 0.8546084793361687
Training loss  0.023180465367965475
Training Loss 0.8892699772923875
Training loss  0.004318982634695434
Training Loss 0.9626024469843195
Training Loss 0.8139350067601472
Training Loss 0.8669030027020345
Training Loss 0.8798822924195451
Training Loss 0.8491616959705723
Training Loss 0.7390191544477288
Training Loss 0.8282035101144197
Training Loss 0.802413443631904
Training Loss 0.6266039500640722
Training Loss 0.7315558325602969
Training Loss 0.8808011462659449
Training loss  0.20929037831425124
Training Loss 0.7415786618583686
Training Loss 0.857607735921073
Training loss  0.17389108997210156
Training Loss 0.6868316885558684
Training Loss 0.751022660546517
Training Loss 0.9061957147820363
Training Loss 0.6024943033854167
Training Loss 0.0618510463149042
Training Loss 0.7738883434632179
Training Loss 0.7181067412582187
Training Loss 0.8148086976089365
Training Loss 0.7176218565867003
Training Loss 0.7677226556346487
Training Loss 0.8257179542824075
Training Loss 0.8201947648948598
Training Loss 0.8165816732146723
Training Loss 0.8468648584242083
Training Loss 0.641555116578558
Training Loss 0.6096971299913194
Training Loss 0.914684487894657
Training Loss 0.8553878041601256
Training Loss 0.9963315357059854
Training Loss 0.9660574490906763
Training Loss 0.7747806779116965
Training Loss 0.9157462623651079
Training Loss 0.6722898469378461
Training Loss 0.9771750549977437
Training Loss 0.8470428997060365
Training loss  0.07764281500817471
Training Loss 0.8488829748639236
Training Loss 0.9239522993582019
Training Loss 0.8035921645847545
Training Loss 0.9386945001330191
Training Loss 0.9141944364188787
Training Loss 0.773710433622543
Training loss  0.11951689805478138
Training Loss 0.8657378684331093
Training Loss 0.8505607616316865
Training Loss 0.877928999973599
Training Loss 0.6770474938716028
Training Loss 0.7813834759790725
Training Loss 0.7012684546246758
Training Loss 0.6512465455529928
Loss and Error 0.6709584872418513 19.16372181135925
saving as ./model10//005_19.1637.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7826366987677215
Training Loss 0.7079731854908251
Training Loss 0.601064571856003
Training Loss 0.8886840112365368
Training Loss 0.6631383287145737
Training Loss 0.8006797525056732
Training Loss 0.8906114890001608
Training Loss 0.5972476254142292
Training Loss 0.9982449613728255
Training Loss 0.6760138078596735
Training Loss 0.7580575321914942
Training loss  0.06167671548661269
Training Loss 0.8193719987715903
Training Loss 0.7866631663665398
Training Loss 0.6332989381824616
Training loss  0.06403478874241264
Training Loss 0.7928388063919658
Training Loss 0.5704293766496612
Training Loss 0.59948252564842
Training Loss 0.8126735740550295
Training Loss 0.7731071345520893
Training Loss 0.892307112111085
Training Loss 0.5380902304318625
Training Loss 0.8919148578902715
Training Loss 0.804051209430496
Training Loss 0.518986482925801
Training Loss 0.8311399508248731
Training loss  0.029247879368567764
Training Loss 0.6847007066217332
Training Loss 0.7363119913143829
Training Loss 0.7035156571132029
Training Loss 0.9842860850507537
Training loss  0.11976302972360808
Training Loss 0.8401433337948708
Training Loss 0.77271125788441
Training loss  0.031164540230661286
Training Loss 0.7835389038427871
Training Loss 0.7087724876805598
Training Loss 0.5595750938017852
Training Loss 0.7641742767725107
Training Loss 0.8105139536061589
Training Loss 0.8511557722657438
Training Loss 0.8301631490982587
Training loss  0.006508912411429479
Training Loss 0.736346171657078
Training Loss 0.7703826661451426
Training Loss 0.471236572265625
Training Loss 0.8947298425572519
Training Loss 0.9681968292827322
Training Loss 0.6960245702493942
Training Loss 0.7710968310199505
Training Loss 0.9150801184492591
Training Loss 0.49935283838041794
Training Loss 0.6160910080890266
Training loss  0.028177470001726546
Training Loss 0.8556171995936532
Training Loss 0.9137464036683165
Training Loss 0.6878642879647133
Training Loss 0.802795538496921
Training Loss 0.9748902188368309
Training Loss 0.9850615481022759
Training Loss 0.7175014508037141
Training loss  0.1530931519693597
Training Loss 0.6525703389713465
Training Loss 0.692073622881356
Training Loss 0.06086607417601204
Training Loss 0.8199831972981211
Training Loss 0.7694015545480689
Training Loss 0.8785699388054249
Training Loss 0.73268294566186
Training Loss 0.7756139192335244
Training Loss 0.037734062706672455
Training Loss 0.8586782044121433
Training Loss 0.7583987078495078
Training loss  0.06698197459446575
Training Loss 0.5898002951910964
Training Loss 0.8434303581549724
Training Loss 0.621734600633907
Loss and Error 0.5834902653574214 20.13279172283143
saving as ./model10//006_20.1328.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5061050969357224
Training Loss 0.9021483819977266
Training Loss 0.7874918908373966
Training Loss 0.7633394099302893
Training Loss 0.8837969668276675
Training Loss 0.6956813226744186
Training Loss 0.8931382276976972
Training Loss 0.6591512356616365
Training Loss 0.9826697221426526
Training Loss 0.7767272191380133
Training Loss 0.8310245256046037
Training Loss 0.5714016974260265
Training Loss 0.860218488874395
Training Loss 0.8719376174076393
Training Loss 0.9154928571775824
Training Loss 0.7899041330945986
Training Loss 0.8772623466394026
Training Loss 0.683696403759438
Training Loss 0.6315750583886658
Training Loss 0.8878355273561037
Training Loss 0.5388526979183782
Training Loss 0.9921196713346411
Training loss  0.009136806476474302
Training Loss 0.6997853379104425
Training Loss 0.770749763184349
Training Loss 0.8730099920152339
Training Loss 0.7172250534247335
Training Loss 0.7034448638178583
Training Loss 0.795888817630597
Training Loss 0.7849010872248872
Training loss  0.06374441714269707
Training Loss 0.7342330400786342
Training Loss 0.7488372197041985
Training Loss 0.8427858119502832
Training Loss 0.9347930854061945
Training Loss 0.7474182412790698
Training Loss 0.7566006702755085
Training loss  0.00043184534348439385
Training Loss 0.5464066299696241
Training Loss 0.5305273151779527
Training Loss 0.9845720313518579
Training Loss 0.8840324793164468
Training Loss 0.96325518836273
Training Loss 0.569659350877739
Training Loss 0.9765736536326142
Training Loss 0.8893248912297804
Training Loss 0.6709184616522083
Training loss  0.072692011443662
Training Loss 0.7624028155193237
Training Loss 0.8452192732744935
Training Loss 0.6863119688555095
Training Loss 0.7484639590873836
Training Loss 0.6442707139267071
Training loss  0.07088998215382247
Training Loss 0.9444482743883018
Training Loss 0.74929653260766
Training Loss 0.6278310333029197
Training Loss 0.7037994818078094
Training Loss 0.7261917076793231
Training Loss 0.9422189786428277
Training Loss 0.6054781257143401
Training Loss 0.6184551017515121
Training Loss 0.9541358773672802
Training Loss 0.7119340038804151
Training Loss 0.7607462913799852
Training Loss 0.8521510743129219
Training Loss 0.6816323605282325
Training Loss 0.9346112342366382
Training Loss 0.9389244502773375
Training Loss 0.7135449569000653
Training Loss 0.8073059018607118
Training Loss 0.9473228835956499
Training loss  0.06238983898628048
Training loss  0.02727893451312635
Training Loss 0.7194181670141859
Training Loss 0.8965642003119955
Training Loss 0.7019477411128549
Training Loss 0.9499783223025837
Loss and Error 0.5640337799791819 20.57543079893621
saving as ./model10//007_20.5754.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6789549438711506
Training Loss 0.775418493259988
Training Loss 0.6966533692540657
Training Loss 0.8035151058586828
Training Loss 0.7700083335364665
Training Loss 0.8305485104049196
Training loss  0.027263468174846706
Training Loss 0.9966704970590589
Training Loss 0.6189466919093636
Training Loss 0.9189498228836764
Training Loss 0.6268450711116911
Training Loss 0.8652516320211423
Training Loss 0.7296218503500529
Training Loss 0.6405372097067636
Training Loss 0.6557734483273021
Training Loss 0.07698104863268782
Training loss  0.024407729893004326
Training Loss 0.8562386890803426
Training Loss 0.9924014162434807
Training Loss 0.9066862218520221
Training Loss 0.6419044129431578
Training Loss 0.6221599905831473
Training Loss 0.9827431816387748
Training Loss 0.5963822895823525
Training Loss 0.5628070931160013
Training loss  0.09518421532289056
Training Loss 0.8905987163569369
Training Loss 0.7450908387926892
Training Loss 0.8874119673194167
Training Loss 0.8981222181798066
Training Loss 0.9177261567946917
Training Loss 0.5870905559820339
Training Loss 0.7121123894502598
Training Loss 0.6923043591237208
Training loss  0.1257076236140915
Training Loss 0.9520703180899399
Training Loss 0.8676946043592362
Training Loss 0.6743155614727508
Training Loss 0.6416789901931024
Training Loss 0.7434128613447615
Training Loss 0.686853737895935
Training Loss 0.8492710169222374
Training Loss 0.8340993877141327
Training Loss 0.5553810753354234
Training Loss 0.7325931840834259
Training loss  0.19307556705914752
Training Loss 0.6718557039209633
Training Loss 0.850321765513147
Training Loss 0.8575220658396947
Training Loss 0.8084758551307847
Training Loss 0.6778894908198121
Training Loss 0.7040902955153601
Training Loss 0.7257187236226212
Training Loss 0.9544458600067386
Training Loss 0.6544923765308591
Training Loss 0.729736862683766
Training Loss 0.8814061003830195
Training Loss 0.8675354319061962
Training Loss 0.8807905949869034
Training Loss 0.6660469022749697
Training Loss 0.7528898496112066
Training loss  0.24833126017312823
Training Loss 0.7905760011472902
Training Loss 0.8547332216508821
Training Loss 0.6053461095984749
Training Loss 0.9283850381540698
Training Loss 0.9702972529549203
Training Loss 0.7816763686475704
Training Loss 0.8669765773667936
Training Loss 0.7187377784192491
Training Loss 0.6118176300125313
Training Loss 0.9259511206810961
Training Loss 0.9109958539021071
Training Loss 0.7044983462677278
Training Loss 0.7701941874419325
Training Loss 0.868171862278032
Training Loss 0.9790786459798818
Training loss  0.07161030719759176
Loss and Error 0.6825285544190298 18.350395278516523
saving as ./model10//008_18.3504.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6132278810952596
Training Loss 0.5542770536819307
Training Loss 0.7104766079764515
Training Loss 0.7167450540046821
Training Loss 0.8752031453782197
Training Loss 0.7335514666904199
Training loss  0.0244572389560076
Training Loss 0.5655322893874364
Training Loss 0.7227427899679298
Training Loss 0.5301307485548541
Training Loss 0.5456159706215323
Training Loss 0.7250566388795799
Training Loss 0.7120190723832831
Training Loss 0.5886032898302023
Training Loss 0.5839340021062586
Training Loss 0.6028261471999514
Training Loss 0.7816656246529834
Training Loss 0.712001056004485
Training Loss 0.936942270041377
Training Loss 0.8003165995445894
Training Loss 0.7592426327862101
Training Loss 0.5035832068773405
Training Loss 0.6907031631593943
Training Loss 0.7761590606360925
Training Loss 0.6389798768463626
Training Loss 0.7668605276031784
Training Loss 0.6178579736084628
Training Loss 0.678655689854203
Training Loss 0.9658162457488895
Training Loss 0.7244757464111179
Training Loss 0.789434903524583
Training Loss 0.7516531988021431
Training Loss 0.7478681949864975
Training Loss 0.6417351272596435
Training Loss 0.737805354769978
Training Loss 0.7055972006315547
Training Loss 0.7230945867178099
Training Loss 0.564732437754065
Training Loss 0.9338648616840028
Training Loss 0.5874155226317476
Training Loss 0.5328475436612896
Training Loss 0.6999206061770735
Training Loss 0.5482375053510274
Training Loss 0.9307758570828764
Training Loss 0.5957438694300734
Training Loss 0.6535396138863429
Training Loss 0.6078061658935139
Training Loss 0.7819106437398703
Training Loss 0.8775087425311163
Training Loss 0.9727154969859995
Training Loss 0.8692549525669643
Training Loss 0.7338871245238919
Training Loss 0.6984715489486322
Training Loss 0.9236518784415269
Training Loss 0.7264394745207355
Training Loss 0.9719193006746414
Training Loss 0.5742136592556901
Training Loss 0.9148839909524088
Training Loss 0.7208755766975938
Training Loss 0.8654809656784976
Training Loss 0.7541963436569633
Training Loss 0.9388874747435851
Training Loss 0.7650380427480037
Training Loss 0.7790084015814741
Training Loss 0.8463292548583911
Training Loss 0.8988235641311814
Training loss  0.10754500135173028
Training Loss 0.7939915248325893
Training Loss 0.7025191724742185
Training Loss 0.692835634660206
Training Loss 0.8754045736763187
Training Loss 0.76008558218062
Training Loss 0.8534914412588444
Training Loss 0.7126815036732616
Training Loss 0.651140101072681
Training Loss 0.8063573701762329
Training Loss 0.7703603345294331
Training Loss 0.7993780685490554
Loss and Error 0.6992511218677411 18.63000473605596
saving as ./model10//009_18.6300.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.9171091891490052
Training Loss 0.3964205613364863
Training Loss 0.7828546391445439
Training Loss 0.6622436312121321
Training Loss 0.9613067229302398
Training Loss 0.6772499341643259
Training Loss 0.6340095668690071
Training Loss 0.9422902974996481
Training Loss 0.6674721013422886
Training loss  0.028422954666325273
Training Loss 0.5919539979834363
Training Loss 0.8560024870728418
Training Loss 0.8788507980223242
Training Loss 0.5785769752236832
Training Loss 0.8662756707285297
Training loss  0.0021739130434783593
Training Loss 0.6723675826340371
Training Loss 0.8919737394141425
Training Loss 0.805877125248623
Training Loss 0.5759445224198744
Training Loss 0.7192144004481245
Training Loss 0.9774468625108816
Training Loss 0.7465159677453115
Training Loss 0.5655237681770968
Training Loss 0.6858549609126668
Training Loss 0.48054167319488755
Training Loss 0.6219585008171479
Training Loss 0.7879597179823622
Training Loss 0.5144794928442333
Training Loss 0.7386284580937138
Training Loss 0.7066636038070923
Training Loss 0.9274809350271593
Training Loss 0.7203254091681826
Training Loss 0.7743682861328125
Training Loss 0.7097546052437441
Training Loss 0.7047560549175501
Training Loss 0.6193805563038793
Training Loss 0.8285671480355472
Training Loss 0.9777678354153148
Training Loss 0.8196661676213298
Training Loss 0.8076056834914922
Training Loss 0.6168056082417793
Training Loss 0.8519896171332629
Training Loss 0.7781405581964447
Training Loss 0.7162224616204108
Training Loss 0.7393840633026542
Training Loss 0.6682671865225212
Training Loss 0.9106814524594411
Training Loss 0.9769426608364207
Training Loss 0.8327073560336461
Training Loss 0.7382301053219347
Training Loss 0.5355831380610335
Training Loss 0.7812225295767345
Training Loss 0.6551481716295812
Training Loss 0.7440795184576023
Training Loss 0.9164707094756872
Training Loss 0.7624092515509128
Training Loss 0.9011007111793463
Training Loss 0.8733241011127104
Training Loss 0.7213833033861885
Training Loss 0.8091831588296856
Training Loss 0.8140381677391105
Training loss  0.026696201679640374
Training Loss 0.5849222532460387
Training Loss 0.9344023586593512
Training Loss 0.8147345751686629
Training Loss 0.7622206996351996
Training Loss 0.8382396282964759
Training Loss 0.9445766360618076
Training Loss 0.9122461578441975
Training Loss 0.7173631171218487
Training Loss 0.5615778058488793
Training Loss 0.8457197149712538
Training Loss 0.6381177654477083
Training Loss 0.6196164042272008
Training Loss 0.9258809964687599
Training Loss 0.7540760497333431
Training Loss 0.552135057385823
Loss and Error 0.6835161261023539 19.21745783088637
saving as ./model10//010_19.2175.w
20Th iteration onwards
teacher_force 0.01
Training loss  0.2123087851654195
Training Loss 0.5633256093128253
Training Loss 0.6280380926306502
Training Loss 0.6924301307547626
Training Loss 0.5020898899641378
Training Loss 0.6053607559913593
Training Loss 0.5759461380356342
Training Loss 0.9207782516348628
Training Loss 0.9041697722623607
Training Loss 0.4427376659798535
Training Loss 0.051457522363507834
Training Loss 0.7351874149206913
Training Loss 0.5472443354203442
Training Loss 0.8014724677073211
Training Loss 0.996148284578296
Training Loss 0.7170481122619445
Training Loss 0.7340943157979286
Training Loss 0.6648145244069343
Training Loss 0.8136256708487347
Training Loss 0.6307601284491857
Training Loss 0.6149627919099769
Training Loss 0.5714893618426615
Training Loss 0.862168023386889
Training Loss 0.5227763744353017
Training Loss 0.5945972274417978
Training Loss 0.7184936006503327
Training Loss 0.9303206820101352
Training Loss 0.9452328286836691
Training Loss 0.7701188218537101
Training loss  0.004518187921336958
Training Loss 0.5971357605921617
Training Loss 0.5319723291575513
Training Loss 0.9793917595135109
Training Loss 0.9395316471233827
Training Loss 0.538502851350628
Training Loss 0.8008515010846188
Training Loss 0.7389922653902622
Training Loss 0.9675320219706998
Training Loss 0.8123272668917602
Training Loss 0.9396677992869399
Training Loss 0.5646528177593478
Training Loss 0.8407227128295192
Training Loss 0.4667946113900244
Training Loss 0.8248729162121873
Training loss  0.04484692860507011
Training Loss 0.8540535025329172
Training Loss 0.8712747135331256
Training Loss 0.7687949855519253
Training Loss 0.8505307008511807
Training Loss 0.7454049546284365
Training Loss 0.8971469346742488
Training Loss 0.9505798124873002
Training Loss 0.5154613968888684
Training Loss 0.8510696165247795
Training loss  0.2791647623400366
Training Loss 0.6675005548306039
Training Loss 0.5756617304104478
Training Loss 0.742743297093718
Training loss  0.014357112412942463
Training Loss 0.7642271180348073
Training Loss 0.7384788839639461
Training Loss 0.6702321148335153
Training Loss 0.6236883868209556
Training Loss 0.6753385745357015
Training Loss 0.9784648630878713
Training Loss 0.8066766457479508
Training Loss 0.9701366698913383
Training Loss 0.7778415155086598
Training Loss 0.8694372076737253
Training Loss 0.779468402665915
Training Loss 0.9282732532118787
Training Loss 0.8909214934978769
Training Loss 0.8326907390992758
Training Loss 0.8767961652690426
Training Loss 0.8437941143487897
Training Loss 0.6702524926144756
Training Loss 0.8710254390119498
Training Loss 0.7939146912167903
Loss and Error 0.5809358002851801 20.763051477285146
saving as ./model10//011_20.7631.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8462155921436916
Training Loss 0.7464508191079295
Training Loss 0.9365228702258205
Training Loss 0.5955561271930242
Training Loss 0.6510577305439168
Training Loss 0.6649727845115069
Training Loss 0.5103561401367187
Training Loss 0.5291790419025126
Training loss  0.0468220048598722
Training Loss 0.8606076886064415
Training Loss 0.7184052395682804
Training Loss 0.7491860115319926
Training loss  0.007149336851310251
Training Loss 0.8399482266054146
Training Loss 0.7202156815695779
Training Loss 0.5736495168585526
Training loss  0.012619263931283431
Training Loss 0.81771079682607
Training Loss 0.7052981243453212
Training Loss 0.5652269648066308
Training Loss 0.49585180783300903
Training Loss 0.737729173209799
Training Loss 0.68621036670108
Training Loss 0.9241917847972732
Training Loss 0.6711442754319035
Training loss  0.020311531736898036
Training Loss 0.8349416330612278
Training Loss 0.7898545229674069
Training Loss 0.8498009753348549
Training Loss 0.7340667002399216
Training Loss 0.4654318583183312
Training Loss 0.4366928989623588
Training loss  0.011716038999845857
Training Loss 0.7867941225724004
Training Loss 0.8092875133737518
Training Loss 0.9408534061679071
Training Loss 0.7277666305465765
Training Loss 0.5859398582673339
Training Loss 0.7133100381194409
Training Loss 0.649057847686356
Training Loss 0.8695611441953982
Training Loss 0.5935014392067743
Training Loss 0.6746990181158002
Training Loss 0.8171890306622257
Training Loss 0.8135809148209708
Training Loss 0.6417326884736647
Training Loss 0.7532601359422783
Training loss  0.024709731759155362
Training Loss 0.6932654159550242
Training Loss 0.8866186153993931
Training Loss 0.08490489627738337
Training Loss 0.8580556481834349
Training Loss 0.8855921310644322
Training Loss 0.6201081748320677
Training Loss 0.751773913963662
Training Loss 0.8186133252240648
Training Loss 0.5884143334735386
Training Loss 0.7188584677892249
Training Loss 0.7435895173445992
Training Loss 0.4962789214122287
Training Loss 0.658579519778921
Training Loss 0.8097281003131547
Training Loss 0.9097439104267923
Training Loss 0.7403585794088724
Training Loss 0.6006411154337276
Training Loss 0.755086759684802
Training Loss 0.8343292936731558
Training Loss 0.481027120214594
Training Loss 0.9202689354224914
Training Loss 0.6868199045613236
Training Loss 0.7693100478238685
Training Loss 0.9658772539375172
Training Loss 0.5684992814189436
Training Loss 0.8639599868591087
Training Loss 0.6604359147645507
Training Loss 0.9869092267022008
Training Loss 0.7177655850237573
Training Loss 0.8082724877353222
Loss and Error 0.556819234165596 21.71754890888557
saving as ./model10//012_21.7175.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7253459907016871
Training Loss 0.8939380323602213
Training Loss 0.5689165600500871
Training Loss 0.5373052440515768
Training Loss 0.4829243619967862
Training Loss 0.7607719202630802
Training Loss 0.9525418344022926
Training Loss 0.6800903081115284
Training Loss 0.7561225288339447
Training Loss 0.693503917755891
Training Loss 0.826718312733209
Training Loss 0.8927983707080178
Training loss  0.0656999510318057
Training Loss 0.8116884802713263
Training Loss 0.8866032950210354
Training Loss 0.5950088500976562
Training Loss 0.7183653580048636
Training Loss 0.6597551088576473
Training Loss 0.7706044281506148
Training Loss 0.6549130839251546
Training Loss 0.6950635652888701
Training Loss 0.7943947447711054
Training Loss 0.6617244021302251
Training loss  0.02684613153824511
Training Loss 0.7072230129377216
Training Loss 0.9209691272079316
Training Loss 0.0680979803079244
Training Loss 0.7389003004983207
Training Loss 0.8161515766791877
Training Loss 0.9007470249282394
Training Loss 0.6811442511612439
Training Loss 0.8230151488382516
Training Loss 0.7931569829969249
Training Loss 0.9803177783051013
Training Loss 0.7671688668725739
Training Loss 0.47723758888434287
Training Loss 0.6711103344797741
Training Loss 0.8868117317572841
Training Loss 0.5967995998222967
Training Loss 0.6127723998447815
Training loss  0.04431593904973741
Training Loss 0.6520523124954206
Training Loss 0.8020892421273378
Training Loss 0.7464687989078661
Training Loss 0.6781645718118224
Training Loss 0.8344023216587658
Training Loss 0.7403634679700719
Training Loss 0.9902653129304407
Training Loss 0.6718586161389329
Training Loss 0.9135965071587067
Training Loss 0.9272167161426439
Training Loss 0.8945072611369249
Training Loss 0.7218132577528247
Training Loss 0.8351294766500934
Training Loss 0.7768889126712328
Training Loss 0.6857945808060161
Training Loss 0.7818705079978646
Training Loss 0.87345216226983
Training Loss 0.9971968112840972
Training Loss 0.731180121462353
Training Loss 0.9857069958238863
Training Loss 0.5943803246412108
Training Loss 0.6567450530983729
Training Loss 0.612488809092328
Training Loss 0.7600329015490391
Training Loss 0.7429352399708495
Training Loss 0.5297405250260584
Training Loss 0.6598624891194138
Training Loss 0.6341301205076867
Training Loss 0.48066821431004725
Training Loss 0.7677530621950511
Training Loss 0.07538776336339664
Training Loss 0.6717150289649386
Training Loss 0.7058562549920128
Training Loss 0.5600175924642474
Training Loss 0.5144822173917354
Training Loss 0.7268429723204085
Training Loss 0.7097170027850014
Loss and Error 0.5702880406493704 20.05264308353674
saving as ./model10//013_20.0526.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8570923168445341
Training Loss 0.6780050417176235
Training Loss 0.6020868691468397
Training Loss 0.6373250872399556
Training Loss 0.6055216739809143
Training Loss 0.7236907015141752
Training Loss 0.8005384914164411
Training Loss 0.5334501510690249
Training Loss 0.8240877396747385
Training Loss 0.6881369838008174
Training Loss 0.6533408576673497
Training Loss 0.5454714416186971
Training Loss 0.6701635660535117
Training Loss 0.7778693081409048
Training Loss 0.7279607522607303
Training Loss 0.9038476960632644
Training Loss 0.5644769583140253
Training Loss 0.6114640611389373
Training Loss 0.6858118543480588
Training Loss 0.8476890470404822
Training Loss 0.8563771630430669
Training Loss 0.7505023080775628
Training Loss 0.6222837867922759
Training Loss 0.5945786609063871
Training Loss 0.6293638542866743
Training loss  0.010483475579651902
Training Loss 0.060579990410604835
Training Loss 0.6851423808107614
Training Loss 0.8605720347775564
Training Loss 0.7101176738097241
Training Loss 0.46974044340510035
Training Loss 0.9131381377330801
Training Loss 0.6558712170369602
Training Loss 0.5090790907290016
Training Loss 0.8084003436170017
Training Loss 0.5419473683913342
Training Loss 0.9240413445886766
Training Loss 0.6287889108038872
Training Loss 0.6376035797440048
Training Loss 0.9457851423487544
Training Loss 0.952132124117257
Training Loss 0.8553808138627663
Training Loss 0.46511623977478084
Training Loss 0.6583906284325571
Training Loss 0.812154716498899
Training Loss 0.6717940326272194
Training Loss 0.44164101543981116
Training Loss 0.5072870240244313
Training Loss 0.6091215053280651
Training Loss 0.7991196801492763
Training Loss 0.6593463625982886
Training Loss 0.8026294893431432
Training Loss 0.9061883708276308
Training Loss 0.6559999792285737
Training Loss 0.656333322616598
Training Loss 0.7506077201066617
Training Loss 0.7390007161458333
Training Loss 0.7736078357667988
Training Loss 0.6632624815407803
Training Loss 0.697308347590349
Training Loss 0.47506157978394414
Training Loss 0.5674876710066878
Training loss  0.01281157350994011
Training Loss 0.7307121642125372
Training Loss 0.829972416279977
Training Loss 0.7087004256449309
Training Loss 0.7865438090973517
Training Loss 0.5855040449556143
Training loss  0.08074620812999123
Training Loss 0.9049018843963977
Training Loss 0.7677641114654971
Training Loss 0.6328111559615852
Training Loss 0.7722903015793011
Training Loss 0.7062205860387638
Training Loss 0.6411331584142876
Training Loss 0.3190840697750869
Training Loss 0.6615662041473639
Training Loss 0.5565280374372531
Loss and Error 0.6977340001292158 18.755692374949906
saving as ./model10//014_18.7557.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7596251124100719
Training Loss 0.5723767724550333
Training Loss 0.911305987202925
Training Loss 0.819748075881807
Training Loss 0.7473550075050034
Training Loss 0.5059802114481553
Training Loss 0.6897925129297149
Training Loss 0.769270399235821
Training Loss 0.6645265580370565
Training Loss 0.8304918751213121
Training Loss 0.8437449151127604
Training Loss 0.6615767244152865
Training Loss 0.7952816370838544
Training Loss 0.6019425150524262
Training Loss 0.5858269471171621
Training Loss 0.6883180823453936
Training Loss 0.8423003420305024
Training Loss 0.5502466696783366
Training Loss 0.5763114042473784
Training Loss 0.6845156238394979
Training Loss 0.9605371878813164
Training loss  0.009522489344641949
Training Loss 0.9232355002951594
Training Loss 0.5715569981941472
Training Loss 0.7680388214326834
Training Loss 0.6291937161904589
Training Loss 0.6800611728022997
Training Loss 0.6572863536527418
Training Loss 0.7249856551891656
Training Loss 0.5504433257977283
Training Loss 0.45717497330970214
Training Loss 0.47440144625138364
Training Loss 0.7140256455579824
Training Loss 0.5507478667468559
Training Loss 0.671142270933273
Training Loss 0.6844914436075201
Training Loss 0.6310996887661066
Training Loss 0.6375556063577891
Training Loss 0.57508448314302
Training Loss 0.47695558320141496
Training Loss 0.5481769434173765
Training Loss 0.6232368649355144
Training Loss 0.8867373631860849
Training Loss 0.8380680047712588
Training Loss 0.6913513278812402
Training Loss 0.45351563306010645
Training Loss 0.6572280421401515
Training Loss 0.6649875987659801
Training Loss 0.32356117001637097
Training Loss 0.765423665719402
Training Loss 0.691841617797006
Training Loss 0.7469780370569545
Training Loss 0.8772723916605087
Training Loss 0.6388394145908941
Training Loss 0.5462224414608574
Training Loss 0.7136828531354866
Training Loss 0.6393222554229542
Training loss  0.06276428086112285
Training Loss 0.6352108811539667
Training Loss 0.8221083842844202
Training Loss 0.6708396992602123
Training Loss 0.7027291517991286
Training Loss 0.688030182793345
Training Loss 0.592699094189888
Training Loss 0.6376209150729495
Training Loss 0.6395358714454076
Training loss  0.008966934321407383
Training Loss 0.802386135155398
Training Loss 0.3498639208663037
Training Loss 0.7017995278666339
Training Loss 0.5744269968422907
Training Loss 0.8466725375186593
Training Loss 0.5579916207901554
Training Loss 0.6292001031624306
Training Loss 0.6504799842168963
Training Loss 0.8503834361273099
Training Loss 0.8362053368538571
Training Loss 0.5654441412241181
Loss and Error 0.6091456352737419 19.688331086742686
saving as ./model10//015_19.6883.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6589038909857904
Training Loss 0.9038530422033503
Training Loss 0.9519283749641628
Training Loss 0.5567377134811047
Training Loss 0.8165186962182971
Training Loss 0.6255893879673378
Training Loss 0.513793830871582
Training Loss 0.6027703319058382
Training loss  0.0721740813617735
Training Loss 0.5447953762692231
Training Loss 0.669701705408498
Training Loss 0.973840748453799
Training Loss 0.723542929283206
Training Loss 0.7158097779927851
Training Loss 0.7215994301139772
Training Loss 0.7487232456545858
Training Loss 0.9449235953836651
Training Loss 0.4052302505573804
Training loss  0.09831487466671351
Training Loss 0.6476275667231134
Training Loss 0.8849689481253914
Training Loss 0.703724952849769
Training Loss 0.38924954412185353
Training Loss 0.5636985045423467
Training Loss 0.6562056039893821
Training Loss 0.5782558518272518
Training Loss 0.6096801930863694
Training Loss 0.5980790834432982
Training Loss 0.7320452669065457
Training Loss 0.6113768789181231
Training Loss 0.8264328139463128
Training Loss 0.7882036028287461
Training Loss 0.7323881682136811
Training Loss 0.6666985405815973
Training Loss 0.6166415744357638
Training Loss 0.9742440463052316
Training Loss 0.726782484831985
Training Loss 0.6087817064713966
Training Loss 0.8262474802669589
Training Loss 0.4377639740993714
Training Loss 0.8929075375018917
Training Loss 0.6200644330896343
Training Loss 0.7370942435530348
Training Loss 0.9361865662691886
Training Loss 0.5654968037768134
Training Loss 0.587804887858012
Training Loss 0.5391291042626728
Training loss  0.04383333333333339
Training Loss 0.7630698752243051
Training loss  0.14956399340840432
Training Loss 0.7954557367634189
Training Loss 0.6149845154755031
Training Loss 0.849203111465238
Training Loss 0.6608558615964532
Training Loss 0.8440417023993516
Training Loss 0.6119283481027158
Training Loss 0.8216248223464733
Training Loss 0.9628405862603305
Training Loss 0.8412923046246985
Training Loss 0.6617418367990836
Training Loss 0.5803885522391382
Training Loss 0.6758788604593232
Training Loss 0.5701341408860495
Training Loss 0.6156423849962875
Training loss  0.0009093178117245415
Training Loss 0.5777928049277726
Training Loss 0.6270825188370771
Training Loss 0.6645313652823082
Training Loss 0.8309544499594412
Training Loss 0.7278581930450541
Training Loss 0.6406179277308389
Training Loss 0.603333213112571
Training Loss 0.7127723090776804
Training Loss 0.5853368766151217
Training Loss 0.6200182393453096
Training Loss 0.7734393402559674
Training Loss 0.59108605141096
Training Loss 0.45723939643591316
Loss and Error 0.5873620721303141 20.151007322671134
saving as ./model10//016_20.1510.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.9303543042685332
Training Loss 0.786036921441798
Training Loss 0.6924711751793806
Training Loss 0.6978547091085686
Training Loss 0.9349792327114086
Training loss  0.025948351625035837
Training loss  0.0765419356319883
Training Loss 0.7130055537840136
Training Loss 0.9478285987778465
Training Loss 0.5761586824042435
Training Loss 0.6235374948974963
Training Loss 0.08273348043893129
Training Loss 0.648726223487652
Training Loss 0.950582589945331
Training Loss 0.8531187559265782
Training Loss 0.484597940953174
Training Loss 0.9260848001475485
Training Loss 0.8192375404539083
Training Loss 0.7088325916807173
Training Loss 0.5611722189653522
Training Loss 0.9431016895411998
Training Loss 0.770199221431943
Training Loss 0.9616887019230769
Training Loss 0.5465202852862262
Training Loss 0.6675315508911499
Training Loss 0.43326241629464285
Training Loss 0.581325099779212
Training Loss 0.6999161091256649
Training Loss 0.7985442439069423
Training Loss 0.6495865027207235
Training Loss 0.6710649634679504
Training Loss 0.5438359056939838
Training Loss 0.9065915502683081
Training Loss 0.4851243781022271
Training Loss 0.6087194332826528
Training Loss 0.9754461412203913
Training Loss 0.590264077644189
Training Loss 0.671388427113152
Training Loss 0.5049248540708221
Training Loss 0.652682074596249
Training Loss 0.6049810280641467
Training Loss 0.7810241244411327
Training Loss 0.5318371929021279
Training Loss 0.7621139836282855
Training Loss 0.6680175033499234
Training Loss 0.59215711994952
Training Loss 0.7914694164322843
Training Loss 0.5574097746469258
Training Loss 0.8950797144156519
Training Loss 0.9847216929200542
Training Loss 0.6809650412908572
Training Loss 0.861288982048083
Training loss  0.11346669583079727
Training Loss 0.76468629451391
Training Loss 0.6917801956310775
Training Loss 0.7496597606650666
Training Loss 0.5561862916347626
Training Loss 0.5566146451484683
Training Loss 0.621675359612901
Training loss  0.0676752251562005
Training Loss 0.4691930065282876
Training Loss 0.5287750131975367
Training Loss 0.6684353438304634
Training Loss 0.5996606677370124
Training Loss 0.9031827439595221
Training Loss 0.739927946081484
Training Loss 0.9800422322494033
Training Loss 0.5753301950633336
Training Loss 0.6914704893563076
Training Loss 0.6993823894108161
Training Loss 0.5286367333574653
Training Loss 0.7937650822711687
Training Loss 0.6832192265822037
Training Loss 0.8433327211152523
Training Loss 0.8094837521861546
Training Loss 0.953165301839814
Training Loss 0.6565764609106697
Training Loss 0.5397290603136186
Loss and Error 0.6468233110892205 18.28664067907756
saving as ./model10//017_18.2866.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7411168924676971
Training Loss 0.6032469565603159
Training Loss 0.6039841265146932
Training Loss 0.4640149227048188
Training Loss 0.6462689854665669
Training Loss 0.9532689498494408
Training Loss 0.8461804451560482
Training Loss 0.7262820251305483
Training Loss 0.6102449851728527
Training Loss 0.7499464916806692
Training Loss 0.6965888318245126
Training Loss 0.8249209640775035
Training Loss 0.7972489753655628
Training Loss 0.6881705974710399
Training Loss 0.5679666824907204
Training Loss 0.7396394263009657
Training Loss 0.8935804258301461
Training Loss 0.625566943317197
Training Loss 0.7666529355677404
Training Loss 0.5043636278617849
Training Loss 0.7921522532077815
Training Loss 0.6254264283267357
Training Loss 0.5204551617304484
Training Loss 0.9229410306270155
Training Loss 0.7994035139515759
Training Loss 0.43343560997784664
Training Loss 0.4965959314430648
Training loss  0.19150856923601633
Training Loss 0.5820895287298387
Training Loss 0.6688103264073092
Training Loss 0.6711782119131546
Training Loss 0.7384890061467271
Training Loss 0.7306390049420451
Training Loss 0.7100498109609208
Training Loss 0.7672777352028459
Training Loss 0.5995739742194985
Training Loss 0.5988837202694296
Training Loss 0.876249955948689
Training Loss 0.6547692187048672
Training Loss 0.6966394067815862
Training Loss 0.7768811380704795
Training Loss 0.5349578627551597
Training Loss 0.7123423043334592
Training Loss 0.9809851812257557
Training Loss 0.8726471306295955
Training Loss 0.542057224656431
Training Loss 0.8393499558971774
Training Loss 0.6121469053337956
Training Loss 0.6460527096941171
Training Loss 0.8132083082695646
Training Loss 0.8121951874203032
Training Loss 0.6188616502277641
Training Loss 0.49185176746530007
Training Loss 0.6213447872528248
Training Loss 0.5066561967434795
Training Loss 0.6138844049812291
Training Loss 0.7881298296559098
Training Loss 0.5621163608420269
Training loss  0.01004174941078917
Training Loss 0.7224069875437062
Training Loss 0.9864895188304645
Training Loss 0.7110972562053438
Training Loss 0.39003649825147785
Training Loss 0.9584996675651191
Training Loss 0.9462650702787527
Training loss  0.08147624527082709
Training Loss 0.8872043409951791
Training Loss 0.5653584853372559
Training Loss 0.4906956722861842
Training Loss 0.9366008297042496
Training loss  0.067040323728492
Training Loss 0.7394693480252443
Training Loss 0.6181410812209471
Training Loss 0.5657802267738917
Training Loss 0.7207781822072387
Training Loss 0.7247289335776749
Training Loss 0.5561057763337545
Training Loss 0.5064690794037856
Loss and Error 0.6293140394704881 18.511603337097892
saving as ./model10//018_18.5116.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.725269675925926
Training Loss 0.5451146481472883
Training Loss 0.9707837806071539
Training Loss 0.5809275870121154
Training Loss 0.5431477586403628
Training Loss 0.8297201717601103
Training Loss 0.7457677982035157
Training Loss 0.6661390335648149
Training Loss 0.8325987075810766
Training Loss 0.6855289631020728
Training Loss 0.06691154596057011
Training Loss 0.6502444850122662
Training Loss 0.9955890871687342
Training Loss 0.4414929732260375
Training Loss 0.503296331171447
Training Loss 0.6573197214226973
Training Loss 0.988435974925835
Training Loss 0.2979078270452449
Training Loss 0.6047519674714938
Training Loss 0.4716895235925286
Training Loss 0.7538234279697937
Training loss  0.04300994094303512
Training Loss 0.5923213714833759
Training Loss 0.8247321255804954
Training Loss 0.7877301707254768
Training Loss 0.6133533487064705
Training Loss 0.6833057742011278
Training Loss 0.45963253945527893
Training Loss 0.8817301046603475
Training Loss 0.7096283495090322
Training Loss 0.47610522886489265
Training Loss 0.935306122393665
Training Loss 0.6706982964215334
Training Loss 0.7122755823196019
Training Loss 0.6538482657436041
Training Loss 0.7629880203832102
Training Loss 0.5757069263643432
Training Loss 0.5962049744500356
Training Loss 0.6397272878916476
Training Loss 0.8419826128072887
Training Loss 0.6354302142999565
Training Loss 0.8237317788687282
Training Loss 0.43886087465061785
Training Loss 0.7740913891364672
Training Loss 0.6418045169407428
Training Loss 0.6963765411419304
Training Loss 0.5174262493688285
Training Loss 0.37085050551837295
Training Loss 0.6560279009110501
Training Loss 0.8822306144962206
Training Loss 0.7191318801096425
Training Loss 0.8121514181994708
Training Loss 0.5428221319842085
Training Loss 0.5326628124745023
Training Loss 0.8418608786513938
Training Loss 0.7399801289742052
Training Loss 0.7587801586413221
Training Loss 0.7185802391353047
Training Loss 0.6885296083080215
Training Loss 0.5920710959885387
Training Loss 0.5210947577708888
Training Loss 0.6688640011995484
Training Loss 0.8042035596930565
Training Loss 0.6631806434101208
Training Loss 0.4172297434193465
Training Loss 0.4308296999947391
Training Loss 0.9373487826888126
Training Loss 0.8364426549001079
Training Loss 0.8925430574008906
Training Loss 0.7767202242864941
Training Loss 0.8594116144122879
Training Loss 0.7467822638358779
Training Loss 0.5814747947348452
Training Loss 0.46536108362481593
Training Loss 0.6358343106563961
Training Loss 0.7152790842714714
Training Loss 0.6567614211532693
Training Loss 0.4052460568683292
Loss and Error 0.5352360657977926 19.850449925316042
saving as ./model10//019_19.8504.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5250047037035053
Training Loss 0.6503393148270288
Training Loss 0.7411394307111762
Training Loss 0.48769081685677423
Training Loss 0.6509731727789256
Training Loss 0.8022693312311747
Training Loss 0.6191466403594945
Training Loss 0.7218992224293563
Training Loss 0.9511273189689191
Training Loss 0.6007850355672545
Training Loss 0.7399629324735838
Training Loss 0.6980551207569826
Training Loss 0.5720025957418433
Training Loss 0.7169255996602438
Training Loss 0.41127508209655406
Training Loss 0.583156828336026
Training Loss 0.5646504323159633
Training Loss 0.5670918923697142
Training Loss 0.8781996627223395
Training Loss 0.7072865357181309
Training Loss 0.5164938176509157
Training Loss 0.9535795057262723
Training Loss 0.448265492491371
Training Loss 0.5574928393382915
Training Loss 0.7439703960023782
Training Loss 0.6834048629821328
Training Loss 0.6533643765939707
Training Loss 0.7123683247479988
Training Loss 0.5391273199973661
Training Loss 0.6864018371057892
Training Loss 0.6082697517097428
Training Loss 0.8459698350694445
Training Loss 0.6844427262401768
Training Loss 0.7067661673849025
Training Loss 0.7476923811082025
Training Loss 0.5856055243107848
Training Loss 0.45685146782661024
Training Loss 0.6763041711413321
Training Loss 0.7115192167910755
Training Loss 0.5648040000578899
Training Loss 0.6558049078458779
Training Loss 0.5539007824650077
Training Loss 0.6854209793379615
Training Loss 0.6560254994915637
Training Loss 0.4869199224278234
Training Loss 0.5800489001338445
Training Loss 0.6620655548878205
Training Loss 0.6066822267403802
Training Loss 0.847205074490152
Training Loss 0.9187184003872634
Training Loss 0.6106249281939338
Training Loss 0.7661231700800962
Training Loss 0.7560688623956326
Training Loss 0.5884934399829874
Training Loss 0.7823686079545454
Training Loss 0.5943819947647977
Training Loss 0.6836472146235163
Training Loss 0.7356276654277469
Training Loss 0.7977542495521228
Training Loss 0.7208090977021767
Training Loss 0.4647973098395504
Training Loss 0.640124152131783
Training Loss 0.7405478072878271
Training Loss 0.5891937429428739
Training Loss 0.6759713357016239
Training Loss 0.5587398639452795
Training Loss 0.6050601684681521
Training Loss 0.7552766848715393
Training Loss 0.666979513146208
Training Loss 0.4659701923461497
Training Loss 0.8284168602488233
Training Loss 0.8279417293481478
Training Loss 0.5841867360302677
Training Loss 0.5027551078298385
Training Loss 0.7436281850791632
Training Loss 0.5273276779363836
Training Loss 0.7509862802836038
Training Loss 0.7014661250878632
Loss and Error 0.6386456128337403 18.90141717366753
saving as ./model10//020_18.9014.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8430636496986996
Training Loss 0.7531330712062124
Training Loss 0.6909507258437158
Training Loss 0.6444211145207976
Training Loss 0.6785513833411654
Training Loss 0.7993523556380648
Training Loss 0.518650234966329
Training Loss 0.7226071246195129
Training Loss 0.5299984482191289
Training Loss 0.509101701271274
Training Loss 0.6838912017292184
Training Loss 0.8134133433488118
Training Loss 0.49030051698580873
Training Loss 0.6306214695214954
Training Loss 0.7505804467871486
Training Loss 0.6499172345006238
Training Loss 0.8314671474220479
Training Loss 0.7185859960420952
Training Loss 0.5981345502068015
Training Loss 0.6427386637611276
Training Loss 0.0915012630118255
Training Loss 0.537099357911538
Training Loss 0.5248214357672469
Training Loss 0.5373460074019095
Training Loss 0.6323175174037489
Training Loss 0.6038238619448725
Training Loss 0.7933996196694904
Training Loss 0.6742987624737395
Training Loss 0.5153255629171214
Training Loss 0.5335388545605353
Training Loss 0.6289646915943697
Training Loss 0.3422322220111449
Training Loss 0.7303472370861872
Training Loss 0.5338952877853922
Training Loss 0.7635339757898352
Training loss  0.1309762179348235
Training loss  0.0019509306365974588
Training Loss 0.5846278001814325
Training Loss 0.7058166679800072
Training Loss 0.5134705794484992
Training Loss 0.6465282280698359
Training Loss 0.5377688837396244
Training Loss 0.679579996820074
Training Loss 0.49199803508676143
Training Loss 0.8228967011144483
Training Loss 0.782137327059202
Training Loss 0.7204666189002606
Training Loss 0.6938827405010153
Training Loss 0.5856876590528901
Training Loss 0.4518790365711655
Training Loss 0.536023034258233
Training Loss 0.5660521361204955
Training Loss 0.5405364191752752
Training Loss 0.8177777700900388
Training Loss 0.5841102108016686
Training Loss 0.655474431662839
Training Loss 0.528972598549306
Training Loss 0.6511192887629443
Training Loss 0.38524760803138003
Training Loss 0.6587415864526834
Training Loss 0.5699958032024793
Training Loss 0.9799409067967698
Training Loss 0.6552398532044654
Training Loss 0.5104295811998711
Training Loss 0.7745339888013456
Training Loss 0.7452213318897919
Training Loss 0.5414431292964936
Training Loss 0.5534843676017992
Training Loss 0.6912225901875195
Training Loss 0.724528639934881
Training Loss 0.7047432495156604
Training Loss 0.7018154046474359
Training Loss 0.42263773491171663
Training Loss 0.572799021537909
Training loss  0.09572647623232444
Training loss  0.060534560214375865
Training Loss 0.4278925530066041
Training Loss 0.8501613303042189
Loss and Error 0.8110513668843897 16.988779190498743
saving as ./model10//021_16.9888.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.8525997837083964
Training Loss 0.44342957765301655
Training Loss 0.4730621383101852
Training Loss 0.5328563485304108
Training Loss 0.6428092937797527
Training Loss 0.46091626872909536
Training Loss 0.9900022781621471
Training Loss 0.4295820579118864
Training loss  0.13164945607440748
Training Loss 0.7421849210497359
Training Loss 0.5783093869966311
Training loss  0.03438327961879151
Training Loss 0.8831796853495734
Training Loss 0.6057203895612334
Training Loss 0.5395416080931145
Training Loss 0.6581123715355283
Training Loss 0.552354592198755
Training Loss 0.5259463635257242
Training Loss 0.6032860303758741
Training Loss 0.7596205923885045
Training Loss 0.7279789014486392
Training Loss 0.658026820541821
Training Loss 0.6442450117515068
Training Loss 0.3821076317285321
Training Loss 0.44132421255318
Training Loss 0.6331886584600553
Training Loss 0.6622034450035311
Training Loss 0.7358135229230475
Training Loss 0.7968817163858322
Training Loss 0.4357269140087319
Training Loss 0.364826669635766
Training Loss 0.6692477227633478
Training Loss 0.7311188853220252
Training Loss 0.7280072783353787
Training Loss 0.07283743857200722
Training Loss 0.7334978536002214
Training Loss 0.5883450415826613
Training Loss 0.8613553535522788
Training Loss 0.4833070890332162
Training Loss 0.4963265666207929
Training Loss 0.4941868091266702
Training Loss 0.7492678004078148
Training Loss 0.6137230079490822
Training Loss 0.4648269952512255
Training Loss 0.9730230622690886
Training Loss 0.36925637997820937
Training Loss 0.816285610628945
Training Loss 0.4447917371257215
Training Loss 0.5166823183378872
Training Loss 0.5194058106095555
Training Loss 0.8931393331520213
Training Loss 0.5989788341046173
Training Loss 0.7471800464768823
Training Loss 0.6848476684952978
Training Loss 0.7959890390602243
Training Loss 0.9287476099668177
Training Loss 0.464559472440128
Training Loss 0.6490098141026839
Training Loss 0.7990227698527478
Training Loss 0.7919701427347047
Training Loss 0.7000581813009229
Training Loss 0.9231148984566954
Training Loss 0.6889911426943469
Training Loss 0.3483812990105464
Training Loss 0.963138598182319
Training Loss 0.47915153813742845
Training Loss 0.7974569995017975
Training Loss 0.6589715021306818
Training Loss 0.5790603411934291
Training Loss 0.9831860486525312
Training Loss 0.5459422907102922
Training Loss 0.6751144971868221
Training Loss 0.48273896542851796
Training Loss 0.5951772836538461
Training Loss 0.5632699119181303
Training Loss 0.7176784854358964
Training Loss 0.07879518156598328
Training Loss 0.9387482099204612
Loss and Error 0.6904653578336497 17.843090822980802
saving as ./model10//022_17.8431.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.439305159810158
Training loss  0.029075907287687386
Training Loss 0.5826536727444356
Training Loss 0.09547995879654926
Training Loss 0.661967054044011
Training Loss 0.6671843158702788
Training Loss 0.5051531141225326
Training Loss 0.7428836133710194
Training Loss 0.5535286112034574
Training Loss 0.6560635888862716
Training Loss 0.8250411760583123
Training Loss 0.6665475827838303
Training Loss 0.6927521479203442
Training Loss 0.7115640603905258
Training Loss 0.8435557567290146
Training loss  0.025300760059705052
Training Loss 0.6207169996072764
Training Loss 0.6678806450229987
Training Loss 0.5564987944402421
Training Loss 0.734601914494191
Training loss  0.04188457048725014
Training Loss 0.6000467573951926
Training Loss 0.6226895995947864
Training Loss 0.4721022569515202
Training Loss 0.69649434361208
Training Loss 0.4876895325401575
Training Loss 0.4236728655368792
Training Loss 0.6017315018078513
Training Loss 0.805980996060056
Training Loss 0.6301149795409855
Training Loss 0.57822144500969
Training Loss 0.8513372726936724
Training Loss 0.6980863400804185
Training Loss 0.7569311299455275
Training Loss 0.3866184861268348
Training Loss 0.6691709346064815
Training Loss 0.6812866457212509
Training Loss 0.49103099447457904
Training Loss 0.9275053544477982
Training Loss 0.6589258489813209
Training Loss 0.4338123779296875
Training Loss 0.7349146792763158
Training Loss 0.5747830738525757
Training Loss 0.7536356478359489
Training Loss 0.46437169071843853
Training Loss 0.587790191488922
Training Loss 0.34150986634097585
Training Loss 0.43400144839827004
Training Loss 0.8278856193494497
Training Loss 0.9245667371221092
Training Loss 0.44195245622008467
Training Loss 0.5895161831345166
Training Loss 0.7764006997128474
Training Loss 0.7533020223662207
Training Loss 0.7948384431897759
Training loss  0.11052195827632261
Training Loss 0.7548305064322771
Training Loss 0.47604686754057923
Training Loss 0.4979451377859687
Training Loss 0.8373398232249032
Training Loss 0.5890142931356028
Training Loss 0.4501390791261716
Training Loss 0.7323737770745286
Training Loss 0.6012422279493344
Training Loss 0.735350677130553
Training Loss 0.422945116091535
Training Loss 0.4446824699527943
Training Loss 0.48724804656527515
Training Loss 0.7197216157604037
Training Loss 0.7929708131602112
Training Loss 0.8903842531630104
Training Loss 0.5722632021216433
Training Loss 0.5553512063069909
Training Loss 0.7398818837806196
Training Loss 0.8488634712535765
Training Loss 0.5567304797911707
Training Loss 0.648213444923868
Training Loss 0.5419029665604956
Loss and Error 0.6398189609208467 19.128201391671826
saving as ./model10//023_19.1282.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.4803403347899011
Training Loss 0.6103408992069298
Training Loss 0.7057757672561573
Training Loss 0.44723352088111623
Training Loss 0.05716194732155425
Training Loss 0.6766346342348505
Training Loss 0.5566355056897888
Training Loss 0.708449876068142
Training Loss 0.07048264224972345
Training Loss 0.5396003949971581
Training Loss 0.654717944599373
Training Loss 0.5351899138206192
Training Loss 0.7579204230908526
Training Loss 0.8332342272345943
Training Loss 0.8306615577955115
Training Loss 0.4506013681038455
Training Loss 0.7578742705195783
Training Loss 0.5740778506337888
Training Loss 0.5492913093258903
Training Loss 0.6000545896410836
Training Loss 0.5358086127739448
Training Loss 0.7008012911733454
Training Loss 0.6194743134304236
Training Loss 0.6051408471164228
Training Loss 0.5139702515280926
Training Loss 0.46683554415411116
Training Loss 0.3997324731248198
Training Loss 0.7895329638629452
Training Loss 0.6283437968309238
Training Loss 0.563351411286025
Training Loss 0.7417518052160925
Training Loss 0.7767031028951091
Training Loss 0.4995204070284697
Training Loss 0.4528080891196712
Training Loss 0.6106074673456957
Training Loss 0.5897304212071893
Training Loss 0.7993743329650989
Training Loss 0.6909907687681921
Training Loss 0.5389055418285345
Training Loss 0.4472600763494318
Training Loss 0.6714491849767366
Training Loss 0.6701399592193564
Training Loss 0.40803480793989483
Training Loss 0.6250725258824877
Training Loss 0.627669359531108
Training Loss 0.5964667815763708
Training Loss 0.8797731199464598
Training Loss 0.7906301897683085
Training Loss 0.595267274477108
Training Loss 0.459794921875
Training Loss 0.5227345271467435
Training Loss 0.8619973790427413
Training Loss 0.5718256542623675
Training Loss 0.6051842349204425
Training Loss 0.5409837231009474
Training Loss 0.7665334963331035
Training Loss 0.97149171375093
Training Loss 0.5182129375901732
Training Loss 0.8727034654281155
Training Loss 0.715273144474899
Training Loss 0.6912413271331562
Training Loss 0.7662469448324022
Training Loss 0.5282746309699051
Training Loss 0.8537185797031546
Training Loss 0.5180745512323567
Training Loss 0.6576684636675099
Training Loss 0.6904822895684124
Training Loss 0.8321583012103735
Training Loss 0.658549700669574
Training Loss 0.7442349927934487
Training Loss 0.5974270303486514
Training Loss 0.4137901357356334
Training Loss 0.5763003700657895
Training Loss 0.705831678752302
Training Loss 0.60227950395604
Training Loss 0.611142571957886
Training Loss 0.6612770974099099
Training Loss 0.7039394073137156
Loss and Error 0.609462929559127 18.806696054501074
saving as ./model10//024_18.8067.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6787849171552067
Training Loss 0.683692012272828
Training Loss 0.43506759252303684
Training Loss 0.7704291800275324
Training Loss 0.42006258093981413
Training Loss 0.6003807513823065
Training Loss 0.6969085929264758
Training Loss 0.8084920993476727
Training Loss 0.9213539366166078
Training Loss 0.5174385579427083
Training Loss 0.49426971132772407
Training Loss 0.6668132036066867
Training Loss 0.5195983452613798
Training Loss 0.6253605972441388
Training Loss 0.426550973309377
Training Loss 0.523725158612854
Training Loss 0.7300671229833197
Training Loss 0.7224627136249608
Training Loss 0.6863753122161671
Training Loss 0.7789410657443683
Training Loss 0.8428465515494752
Training Loss 0.7162007336935206
Training Loss 0.8627259065276361
Training Loss 0.768227443222172
Training Loss 0.4121886897208122
Training Loss 0.8631797329215116
Training Loss 0.6532741722935679
Training Loss 0.5939487094792845
Training Loss 0.6309468330706434
Training Loss 0.4592263178378662
Training Loss 0.5577468760822215
Training Loss 0.6398034480286123
Training Loss 0.4408353997548825
Training Loss 0.8348305388036062
Training Loss 0.5307263889501058
Training Loss 0.6769349556114084
Training Loss 0.7151469983552632
Training Loss 0.471841507181598
Training Loss 0.7784959516055667
Training Loss 0.5570246234201811
Training Loss 0.7267504436213795
Training Loss 0.6752680489623987
Training Loss 0.7054307432432433
Training Loss 0.5624413826258694
Training Loss 0.5201737273442402
Training Loss 0.5539552234468006
Training Loss 0.31055702035099436
Training Loss 0.593717807150184
Training Loss 0.9211558790283566
Training Loss 0.5213618147263833
Training Loss 0.7072703380994627
Training Loss 0.43609965861344535
Training Loss 0.5994314277144648
Training Loss 0.6058578191657543
Training Loss 0.5659499560131905
Training Loss 0.5152021593054451
Training Loss 0.557287867081388
Training Loss 0.6065745769249609
Training Loss 0.9019775739496999
Training Loss 0.578879300879423
Training Loss 0.4898221895292208
Training Loss 0.4869280187668529
Training Loss 0.3108432517608342
Training Loss 0.9328097452397743
Training Loss 0.440473506723982
Training Loss 0.42548494061914244
Training Loss 0.4664878657298722
Training Loss 0.7716868758415619
Training Loss 0.9863319455498236
Training Loss 0.43144012266098786
Training Loss 0.7830681403592534
Training Loss 0.5815048195194584
Training Loss 0.8145975136305045
Training Loss 0.7846653472909014
Training Loss 0.5105956671027757
Training Loss 0.45246977436401525
Training Loss 0.7659184626971139
Training Loss 0.5225978433523377
Loss and Error 0.6528326434355838 18.228350759590512
saving as ./model10//025_18.2284.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.780559629341806
Training Loss 0.5808408799453976
Training Loss 0.6111314150869738
Training Loss 0.4845704195792215
Training Loss 0.24172415408152087
Training Loss 0.8230097771494802
Training Loss 0.7051189464010706
Training Loss 0.6217753005577498
Training Loss 0.4444133820040302
Training Loss 0.7198086325727127
Training Loss 0.6485721088215761
Training Loss 0.7592601713723419
Training Loss 0.5258837001325057
Training Loss 0.45140323871450344
Training Loss 0.7592444557136068
Training Loss 0.5988882941780759
Training Loss 0.5108505579709268
Training Loss 0.7232955909178187
Training Loss 0.44417455454941207
Training Loss 0.6554295764298994
Training Loss 0.6908982776884862
Training Loss 0.6796622932731331
Training Loss 0.8452308494727928
Training loss  0.025034453490070163
Training Loss 0.6576032764788282
Training Loss 0.4518032420551663
Training loss  0.06163242533742941
Training Loss 0.6779615018590651
Training Loss 0.6710965580071885
Training Loss 0.3756199780968891
Training Loss 0.7925604818283967
Training Loss 0.6167802120278949
Training Loss 0.7188541128615702
Training Loss 0.5562852986358191
Training Loss 0.5217033201372271
Training Loss 0.6686822247651457
Training Loss 0.5083247580006949
Training Loss 0.6419063270723051
Training Loss 0.699688861013829
Training Loss 0.5924625281131629
Training Loss 0.8067488910320456
Training Loss 0.41409940674970747
Training Loss 0.739858826754386
Training Loss 0.6969493138610254
Training Loss 0.7603580981753152
Training Loss 0.5932502297794118
Training Loss 0.6905511299167927
Training Loss 0.41664728055334393
Training Loss 0.4540317217508952
Training Loss 0.5144164498928374
Training Loss 0.645259208082977
Training Loss 0.5726458178783382
Training Loss 0.6342231433040701
Training Loss 0.45195769549531983
Training Loss 0.8571216647355961
Training Loss 0.7004947201236263
Training Loss 0.41271770613903097
Training Loss 0.7859036303108539
Training Loss 0.6267186804662777
Training Loss 0.6042514774224239
Training Loss 0.5136308636919797
Training Loss 0.6907377860915493
Training Loss 0.6095247643377694
Training Loss 0.6504875243355148
Training Loss 0.0940960914857926
Training Loss 0.7054769151393517
Training Loss 0.7740852960043988
Training Loss 0.6342000830225444
Training Loss 0.5625158633369651
Training Loss 0.5683915454456324
Training Loss 0.5207922373717583
Training Loss 0.8647825873124833
Training Loss 0.6634280065975279
Training Loss 0.6393567126832029
Training Loss 0.5670978321748621
Training Loss 0.6558760264865181
Training Loss 0.5104258478952121
Training Loss 0.6981399171258283
Loss and Error 0.6109516499032912 18.592662756384566
saving as ./model10//026_18.5927.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6833982312254828
Training Loss 0.40526936242548434
Training Loss 0.4455058639264128
Training Loss 0.89818674329493
Training Loss 0.5673150919131826
Training Loss 0.3652208234261775
Training Loss 0.42378840226829495
Training Loss 0.5455440337245293
Training Loss 0.5949768407384777
Training Loss 0.6135854275427132
Training Loss 0.590645242778931
Training Loss 0.5937243239622277
Training Loss 0.6621725159975456
Training Loss 0.5368062105843541
Training Loss 0.7256677583953821
Training Loss 0.6001035084223264
Training Loss 0.7217898742590656
Training Loss 0.5768189084945764
Training Loss 0.6233273281341858
Training Loss 0.5421602494793231
Training Loss 0.6832180585866947
Training Loss 0.5578328998134874
Training Loss 0.9044013390174279
Training Loss 0.546590908330299
Training Loss 0.8505153650414101
Training Loss 0.5323976191901149
Training Loss 0.7183077817079895
Training Loss 0.4780893986664612
Training Loss 0.7106148905936963
Training Loss 0.5311057350852273
Training Loss 0.760274771714189
Training Loss 0.5495685992059267
Training Loss 0.6485827719710686
Training Loss 0.6309426064192981
Training Loss 0.6823670956815874
Training Loss 0.7842038172312716
Training Loss 0.6673595496938698
Training Loss 0.632167397267642
Training Loss 0.5778905650531643
Training Loss 0.4910121348912021
Training Loss 0.3444460588160569
Training Loss 0.6198182066347754
Training Loss 0.5760699886289397
Training Loss 0.48919609036796535
Training Loss 0.5660837123121334
Training Loss 0.7051230412866595
Training Loss 0.5764174844887983
Training Loss 0.5054008453895147
Training Loss 0.4454566118988017
Training Loss 0.965049265391791
Training Loss 0.5711476325425465
Training Loss 0.47312312655978733
Training Loss 0.46622889727011496
Training Loss 0.7292153751148897
Training Loss 0.6142488487750419
Training Loss 0.7394600591715976
Training Loss 0.5281178679578715
Training Loss 0.7347868546195652
Training Loss 0.6266625774793388
Training Loss 0.06590153936129897
Training Loss 0.4725022938748782
Training Loss 0.5012322545356458
Training Loss 0.5138733798401767
Training Loss 0.7543555588438287
Training Loss 0.4087507471058121
Training Loss 0.5388051646945955
Training Loss 0.6250799668409126
Training Loss 0.49813597797234754
Training loss  0.06099000792572462
Training Loss 0.6952758392144546
Training Loss 0.7562857271986673
Training Loss 0.6155605827931866
Training Loss 0.3666211276691269
Training Loss 0.7247789952143324
Training Loss 0.5173745425112612
Training Loss 0.5360913150524967
Training Loss 0.5906962656604193
Training Loss 0.9538168853183963
Loss and Error 0.5733006342751648 19.465189988706328
saving as ./model10//027_19.4652.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5294808814218523
Training Loss 0.4972502263022699
Training Loss 0.7618223202154503
Training Loss 0.6601913099479969
Training Loss 0.8458405768264075
Training Loss 0.470314217172745
Training Loss 0.49872471755609776
Training Loss 0.5250835901917876
Training Loss 0.49917177800237583
Training Loss 0.8490820616251944
Training Loss 0.6548507482544278
Training Loss 0.5041977071408417
Training Loss 0.639357855519361
Training Loss 0.704199306864688
Training Loss 0.39602013049155693
Training Loss 0.6112305669627891
Training Loss 0.677347480329407
Training Loss 0.8238929271561876
Training Loss 0.8467900887695918
Training Loss 0.5002106297382836
Training Loss 0.49492681547737793
Training Loss 0.6392590391869638
Training Loss 0.4976818217366965
Training Loss 0.7432475287989343
Training Loss 0.39509171381171715
Training Loss 0.4404040483328012
Training Loss 0.5649611135792303
Training Loss 0.42966149504620926
Training Loss 0.7337843986050195
Training Loss 0.6966589035526398
Training Loss 0.6538954305305755
Training Loss 0.602926367947926
Training Loss 0.4207654280963595
Training Loss 0.6569523139927412
Training Loss 0.5472983408704754
Training Loss 0.5736234927605726
Training Loss 0.5388423071967231
Training Loss 0.7163636457514647
Training Loss 0.7842429560962807
Training Loss 0.06882792724084019
Training Loss 0.709715884354825
Training Loss 0.5547694591325796
Training Loss 0.43329814685931617
Training Loss 0.4399776997238803
Training Loss 0.7033288244885858
Training Loss 0.5234215229867332
Training Loss 0.6236750293128058
Training Loss 0.6851359826314598
Training Loss 0.6768008394105135
Training Loss 0.6474236039645827
Training Loss 0.7355499182665554
Training Loss 0.7293914744645799
Training Loss 0.5949492394023792
Training Loss 0.6309569740909423
Training Loss 0.78496004127745
Training Loss 0.3695778985939622
Training Loss 0.6356781202056546
Training Loss 0.47683263604443554
Training Loss 0.6715343997497011
Training Loss 0.6379598556165302
Training Loss 0.5204307469030384
Training Loss 0.5197786070322302
Training Loss 0.8672556403277613
Training Loss 0.6370890966530055
Training Loss 0.548344908290116
Training Loss 0.38689137169607696
Training Loss 0.6230595324889447
Training Loss 0.5974596101624542
Training Loss 0.6984253935872073
Training Loss 0.6510701233018311
Training Loss 0.5778313380308624
Training Loss 0.833790755645274
Training Loss 0.5416529392604233
Training Loss 0.5549045466111279
Training Loss 0.4950992613527266
Training Loss 0.5303870804398149
Training Loss 0.8663532762242828
Training Loss 0.4336660038720596
Loss and Error 0.632865097080582 19.48704870851397
saving as ./model10//028_19.4870.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.593653363954585
Training Loss 0.6422454258181014
Training Loss 0.7224393638092637
Training Loss 0.6972812465603904
Training Loss 0.457321221353453
Training Loss 0.3787917770981135
Training Loss 0.8409048938528919
Training Loss 0.616462540280565
Training Loss 0.4497056753096682
Training Loss 0.5740421028560786
Training Loss 0.5640575407691759
Training Loss 0.3672517829602633
Training Loss 0.5670927889817788
Training Loss 0.4564134812567513
Training Loss 0.39295841471354165
Training Loss 0.4459388601056845
Training Loss 0.5343151778045718
Training Loss 0.8333534917335627
Training Loss 0.4898832514044944
Training Loss 0.662111003133641
Training Loss 0.5397148744831808
Training loss  0.038677297125519594
Training Loss 0.7079318576388889
Training Loss 0.6708057186030276
Training Loss 0.5768663211356375
Training Loss 0.45585998994598653
Training Loss 0.8835967009231149
Training Loss 0.4518889583824543
Training Loss 0.6637563773726507
Training Loss 0.7378434397734162
Training Loss 0.8350116436298077
Training Loss 0.6591064783826829
Training Loss 0.8435302580923947
Training Loss 0.6546805465304033
Training Loss 0.42026586732994053
Training Loss 0.46231149726895554
Training Loss 0.5753189536343651
Training Loss 0.5750786471079631
Training Loss 0.4720919237169129
Training Loss 0.38440196947966987
Training Loss 0.41425033014909163
Training Loss 0.5235549403126881
Training Loss 0.8321244754396315
Training Loss 0.5153084660988811
Training Loss 0.4848031025271866
Training Loss 0.6336701281517603
Training Loss 0.37745483286549036
Training Loss 0.7392082467900302
Training Loss 0.40454117514190624
Training Loss 0.41961109434373023
Training Loss 0.6905725390132409
Training Loss 0.5910922563383209
Training Loss 0.5085990601781923
Training Loss 0.8158352999390986
Training Loss 0.713390106028448
Training Loss 0.6138935151166445
Training Loss 0.5465107128586827
Training Loss 0.5145814170098766
Training Loss 0.5337429067250845
Training Loss 0.7453060211872977
Training Loss 0.5604287756494729
Training Loss 0.5709437731043673
Training Loss 0.5365266279740767
Training Loss 0.4579000964985181
Training loss  0.03619076252124587
Training Loss 0.6388614688907658
Training Loss 0.4770213874379603
Training Loss 0.6615370803792349
Training Loss 0.49794541246309054
Training Loss 0.47798823037080757
Training Loss 0.5545464072964309
Training Loss 0.5686152898348295
Training Loss 0.3264000087556141
Training Loss 0.32429392177010224
Training Loss 0.5420888280307884
Training Loss 0.39015837755248445
Training Loss 0.5592003947533678
Training Loss 0.8832924094213392
Loss and Error 0.610229944245078 19.92149076469088
saving as ./model10//029_19.9215.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.81926924042142
Training Loss 0.3205048056209789
Training Loss 0.5279052122301983
Training Loss 0.39542363376350426
Training Loss 0.6087007500052733
Training Loss 0.503516202385946
Training Loss 0.5910153125454479
Training Loss 0.4690132756045025
Training Loss 0.7437546565438213
Training Loss 0.7236551256491098
Training Loss 0.5219060789864018
Training Loss 0.6324563435777987
Training Loss 0.392481267491635
Training Loss 0.7737109317706805
Training Loss 0.48539911314498546
Training Loss 0.6319378602851942
Training Loss 0.7653046133448116
Training Loss 0.32695591644453265
Training Loss 0.758430998907906
Training Loss 0.5258659225503093
Training Loss 0.5247612873869311
Training Loss 0.5250668818896642
Training Loss 0.46716870453587656
Training Loss 0.268374528305181
Training Loss 0.5705222771327741
Training Loss 0.655856579115542
Training Loss 0.4751876920039572
Training Loss 0.43778651310847355
Training Loss 0.6897371196311358
Training Loss 0.8594307804739238
Training Loss 0.3967001038978542
Training Loss 0.8452852491439645
Training Loss 0.5863490331461914
Training Loss 0.6014536073083907
Training Loss 0.4940183995790978
Training Loss 0.7042829740030401
Training Loss 0.8333940592942629
Training Loss 0.7831538372788868
Training Loss 0.6238382781498016
Training Loss 0.5347993836280257
Training Loss 0.48803834350840025
Training Loss 0.4188243833870559
Training Loss 0.32712747553762367
Training Loss 0.782205436180793
Training Loss 0.6397697197778973
Training Loss 0.49509394319938177
Training Loss 0.552828146032755
Training Loss 0.5594792122503089
Training Loss 0.3799291206748492
Training Loss 0.6259182260514461
Training Loss 0.46478227353328355
Training Loss 0.7030353325546544
Training Loss 0.5347466370707766
Training Loss 0.6217519658791555
Training Loss 0.7973491790340761
Training Loss 0.793753029907518
Training Loss 0.6014845086165229
Training Loss 0.7259821293641926
Training Loss 0.5075404181916988
Training Loss 0.4947836686117936
Training Loss 0.7201793957806456
Training Loss 0.45777296875
Training Loss 0.4186657848660171
Training Loss 0.4929269041223188
Training Loss 0.7949070356645159
Training Loss 0.8460630598288882
Training Loss 0.5616760467465229
Training Loss 0.5113067951838627
Training Loss 0.5035598759832144
Training Loss 0.5418506460858536
Training Loss 0.8705832626776486
Training Loss 0.8715128249543924
Training Loss 0.698121024514008
Training Loss 0.6067768999897906
Training Loss 0.6818398101271903
Training Loss 0.6078602903249359
Training Loss 0.45701477110057864
Training Loss 0.34906573409020697
Loss and Error 0.6802754476292192 18.059856461073263
saving as ./model10//030_18.0599.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5435444116246372
Training Loss 0.6760084801113483
Training Loss 0.6619807011930062
Training Loss 0.5966542665984206
Training Loss 0.5722401000935723
Training Loss 0.39672833876276803
Training Loss 0.7066222827941578
Training Loss 0.5346780143338955
Training Loss 0.6634406252026064
Training Loss 0.6002233813622755
Training Loss 0.47906528898686646
Training Loss 0.5729393917863452
Training Loss 0.4436309264107039
Training Loss 0.3725514298327644
Training Loss 0.5167075430992807
Training Loss 0.5146481588915267
Training Loss 0.6971570577404114
Training Loss 0.6718565450537363
Training Loss 0.5152267682446217
Training Loss 0.35307359945087535
Training Loss 0.6770503261472114
Training Loss 0.5979830049667336
Training Loss 0.5600504454797701
Training Loss 0.2872833549732452
Training Loss 0.49598074610999704
Training Loss 0.8380214793330509
Training Loss 0.7966139279222595
Training Loss 0.786630269706947
Training Loss 0.49687478050001815
Training Loss 0.571489699134569
Training Loss 0.7010717033617424
Training Loss 0.06752390992694837
Training Loss 0.39039185441206525
Training Loss 0.5342135660448789
Training Loss 0.47178166634208213
Training Loss 0.4507558043573944
Training Loss 0.5350241685334668
Training Loss 0.5384054928827224
Training Loss 0.7312117503741448
Training Loss 0.40515365924061175
Training Loss 0.46475748650506116
Training Loss 0.34418377609452017
Training Loss 0.737375968516671
Training loss  0.18532780454384734
Training Loss 0.5091228706756499
Training Loss 0.47438925653518876
Training Loss 0.6961746945207935
Training Loss 0.4889473228705992
Training Loss 0.7931914328231292
Training Loss 0.4846172124183627
Training Loss 0.474698745626417
Training Loss 0.9245128761574074
Training Loss 0.5415245280617289
Training Loss 0.3573676548121166
Training Loss 0.39175369676297
Training Loss 0.4924173570399444
Training Loss 0.3237335776836029
Training Loss 0.5053389338894331
Training Loss 0.7162612646123507
Training Loss 0.6839670871627485
Training Loss 0.2946562823127298
Training Loss 0.5515793933568455
Training Loss 0.4614487132144745
Training Loss 0.7982488464836321
Training Loss 0.5367782610252004
Training Loss 0.7611817232445008
Training Loss 0.663316443215754
Training Loss 0.6069413282326102
Training Loss 0.07370587917055786
Training Loss 0.7038011235438534
Training Loss 0.640889949729892
Training Loss 0.4831517273249556
Training Loss 0.6218810273274965
Training Loss 0.7229613345478326
Training Loss 0.8551402515491295
Training Loss 0.8156406014614564
Training Loss 0.5675294235368028
Training Loss 0.7162822641339746
Loss and Error 0.6509147197930389 17.18915078873547
saving as ./model10//031_17.1892.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7347340856481481
Training Loss 0.7583562124156644
Training Loss 0.4275559905864792
Training Loss 0.6566608384179072
Training Loss 0.4404204382367471
Training Loss 0.5342725503324258
Training Loss 0.690363475471949
Training Loss 0.5041789279513889
Training Loss 0.5306913424034175
Training Loss 0.7658640908907283
Training Loss 0.4332528520102466
Training Loss 0.5270361631979674
Training Loss 0.45563389162091317
Training Loss 0.6881088287703346
Training Loss 0.9398554225591244
Training Loss 0.9844094708954577
Training Loss 0.3702526848652987
Training Loss 0.6032211477388212
Training Loss 0.5507891682915912
Training Loss 0.6279866386586863
Training Loss 0.4557627141138165
Training Loss 0.7300267633402122
Training Loss 0.6834114456070232
Training Loss 0.8872662284592613
Training Loss 0.4727029049678373
Training Loss 0.39333998025262085
Training Loss 0.7452092991643773
Training Loss 0.5455001149988129
Training Loss 0.5936155962470263
Training Loss 0.619648897574313
Training Loss 0.6448508050362105
Training Loss 0.6293749348110347
Training Loss 0.6153740243448049
Training Loss 0.43664997841984793
Training Loss 0.4461676449699198
Training Loss 0.553838951853845
Training Loss 0.5224057204431767
Training Loss 0.6772939730474589
Training Loss 0.48579668076657456
Training Loss 0.4705323251719749
Training Loss 0.6757793318105357
Training Loss 0.6456373393586894
Training Loss 0.39648562792109604
Training Loss 0.8026059523160877
Training Loss 0.44397158141529885
Training Loss 0.48051445530794007
Training Loss 0.46138096120181643
Training Loss 0.5187946071077107
Training Loss 0.6619237140183788
Training Loss 0.8970661626483167
Training Loss 0.37550468595602765
Training Loss 0.6677945026647658
Training Loss 0.7116844974347015
Training Loss 0.5499537056739178
Training Loss 0.5234538569072756
Training Loss 0.5656811907859621
Training Loss 0.5978875823909261
Training Loss 0.6792283440555044
Training Loss 0.650275622110867
Training Loss 0.8188382635300029
Training Loss 0.7953356399858956
Training Loss 0.3872064716153295
Training Loss 0.6700824005435212
Training Loss 0.40116531530865657
Training Loss 0.4916781624146742
Training Loss 0.7955453676196588
Training Loss 0.712211132338728
Training Loss 0.642962803574231
Training Loss 0.6076385214601877
Training Loss 0.6582003196344874
Training Loss 0.8878333802206316
Training Loss 0.9049222405581551
Training Loss 0.549941267355232
Training Loss 0.5259547930255118
Training Loss 0.485876202583313
Training Loss 0.39942006406594704
Training Loss 0.483296167026622
Training Loss 0.5553281816862139
Loss and Error 0.6814612214048115 17.975153921818645
saving as ./model10//032_17.9752.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5110857524195879
Training Loss 0.6779273588859911
Training Loss 0.32133011906783776
Training Loss 0.7558087455020263
Training Loss 0.6353246209905011
Training Loss 0.5146475897894965
Training Loss 0.6542231832930878
Training Loss 0.5164798216126312
Training Loss 0.6231034256304483
Training Loss 0.5631784062881865
Training Loss 0.32957832499132705
Training Loss 0.36065629276916056
Training Loss 0.5140274131232924
Training Loss 0.41979732455034097
Training loss  0.037836148786249524
Training Loss 0.6275323979369777
Training Loss 0.7347132607858243
Training Loss 0.56116145410579
Training Loss 0.5361123511205048
Training Loss 0.5650298684641049
Training Loss 0.8342793540924386
Training Loss 0.04630170676620741
Training Loss 0.6291288231517944
Training Loss 0.5175945832045484
Training Loss 0.4795011876733626
Training Loss 0.4856853903096165
Training Loss 0.798197048205586
Training Loss 0.3113110226841874
Training Loss 0.6458129138481327
Training Loss 0.6237000234525613
Training Loss 0.7899129219090838
Training Loss 0.4930214751681364
Training Loss 0.4835505282981675
Training Loss 0.4472521879064554
Training Loss 0.5386814914588073
Training Loss 0.664114920468898
Training Loss 0.48496408173532196
Training Loss 0.45521629292282334
Training Loss 0.4826405461362016
Training Loss 0.48747422023372755
Training Loss 0.6882803575047907
Training Loss 0.6215040128679182
Training Loss 0.5143413837139423
Training Loss 0.07527296768749529
Training Loss 0.7502803388985796
Training Loss 0.36029882026655835
Training Loss 0.5952334828711257
Training Loss 0.6338007156470978
Training Loss 0.7125496106702474
Training Loss 0.3041644267228217
Training Loss 0.7478155111828148
Training Loss 0.6505230718061635
Training Loss 0.7118938131893382
Training Loss 0.5571652903882279
Training Loss 0.7224513202799091
Training Loss 0.9192376875949848
Training Loss 0.71305580517247
Training Loss 0.7222423749151328
Training Loss 0.49748766897955715
Training Loss 0.6930862408172198
Training Loss 0.6140436368209256
Training Loss 0.5749098833869485
Training Loss 0.6930070431401074
Training Loss 0.6359719066484425
Training Loss 0.780536940117844
Training Loss 0.531989704668685
Training Loss 0.7574321166913887
Training Loss 0.46570300118858954
Training Loss 0.38289219481940334
Training Loss 0.6848178410860946
Training Loss 0.5496904588736689
Training Loss 0.08838134381756092
Training Loss 0.4614326968213519
Training Loss 0.5496046134445033
Training Loss 0.5722300161179592
Training Loss 0.5371238325691
Training Loss 0.13413685444392873
Training Loss 0.5546637398177164
Loss and Error 0.5814654728518813 19.43331268898685
saving as ./model10//033_19.4333.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5268743937953598
Training Loss 0.4136447717163985
Training Loss 0.9077832633088713
Training Loss 0.8321973159480146
Training Loss 0.41143026792854026
Training Loss 0.6395222794258832
Training Loss 0.31772291163294375
Training Loss 0.2452360258082994
Training Loss 0.4378183983021014
Training Loss 0.8763678880256028
Training Loss 0.3480153235503547
Training Loss 0.7046868669408822
Training Loss 0.17722133250603703
Training Loss 0.6495577804089944
Training Loss 0.9070299950033622
Training Loss 0.5472951370671564
Training Loss 0.5965398903298406
Training Loss 0.9314937501157065
Training Loss 0.8452017844260276
Training Loss 0.5582457078528786
Training Loss 0.5244517125389129
Training Loss 0.6223001837186073
Training Loss 0.49331994933990136
Training Loss 0.36506255302871415
Training Loss 0.8910586278978831
Training Loss 0.5516858511979303
Training Loss 0.32642834380016783
Training Loss 0.5011268292281991
Training Loss 0.7307130321968324
Training Loss 0.6103636188271605
Training Loss 0.7291445274365441
Training Loss 0.6914822439691186
Training Loss 0.6315343201259717
Training Loss 0.4414015108431908
Training Loss 0.37698812724014336
Training Loss 0.6826151142949644
Training Loss 0.4233654078298455
Training Loss 0.40940900393681534
Training Loss 0.4902699893282861
Training Loss 0.6419838064361553
Training Loss 0.6002488236098095
Training Loss 0.8049290826030432
Training Loss 0.5654929915514593
Training Loss 0.5807511481433614
Training Loss 0.5905280189106118
Training Loss 0.6220227560182189
Training Loss 0.8855535653245539
Training Loss 0.042900489483428984
Training Loss 0.7177610790573667
Training Loss 0.5107565487132353
Training Loss 0.6606997736290069
Training Loss 0.42319683896832333
Training Loss 0.6304736993831506
Training Loss 0.48462163257214996
Training Loss 0.3596311742307553
Training Loss 0.6082258271657696
Training Loss 0.6003171814727987
Training Loss 0.334124854666643
Training Loss 0.4044666536710675
Training Loss 0.5869846640249929
Training Loss 0.5073354510262428
Training Loss 0.45867561540198737
Training Loss 0.5392981978402286
Training Loss 0.5481268427414685
Training Loss 0.3534732315891473
Training Loss 0.5593094544944878
Training Loss 0.5540508982198816
Training Loss 0.5950757921180444
Training Loss 0.6560120409916962
Training Loss 0.4412205943158078
Training Loss 0.7441659448720056
Training Loss 0.7241248604910714
Training Loss 0.37630802698076293
Training Loss 0.2973184927239649
Training Loss 0.5370501225628576
Training Loss 0.6749787671638258
Training Loss 0.47769131760241673
Training Loss 0.499810063237244
Loss and Error 0.6794597333941954 18.9460453932748
saving as ./model10//034_18.9460.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.39648351001992915
Training Loss 0.3714574697066326
Training Loss 0.4382737866337435
Training Loss 0.3391795293522267
Training Loss 0.5385534157706994
Training Loss 0.6754512786865234
Training Loss 0.6386258763944841
Training Loss 0.3160859018545469
Training Loss 0.4290809942933197
Training Loss 0.5532634618416903
Training Loss 0.652926684700869
Training Loss 0.63787261475908
Training Loss 0.7412408886933785
Training Loss 0.7584169861150367
Training Loss 0.46744500211967055
Training Loss 0.34001261789818876
Training Loss 0.8353981438893255
Training Loss 0.45923487451077166
Training Loss 0.7902989002650479
Training Loss 0.5641409301757813
Training Loss 0.10769195127084474
Training Loss 0.5320783578929539
Training Loss 0.41047169784277154
Training Loss 0.5165492160039543
Training Loss 0.40546144466184564
Training Loss 0.3618181988909528
Training Loss 0.6889336895277364
Training Loss 0.4969508297128273
Training Loss 0.6220114761257765
Training Loss 0.6939911404329877
Training Loss 0.5229029278520592
Training Loss 0.5648472230309259
Training Loss 0.6208655777687143
Training Loss 0.5735861964419554
Training Loss 0.5491459368135982
Training Loss 0.5519119758678895
Training Loss 0.11152111201864631
Training Loss 0.3201151368595665
Training Loss 0.5377302389001686
Training Loss 0.553971322098079
Training Loss 0.5468507051759005
Training Loss 0.4244379458220109
Training Loss 0.5922685825373915
Training Loss 0.6452441012020617
Training Loss 0.7790797666586873
Training Loss 0.5403069814046224
Training Loss 0.6844624863765075
Training Loss 0.7751839590587691
Training Loss 0.4688441037393576
Training Loss 0.4482578064343944
Training Loss 0.531041965811306
Training Loss 0.948567778367936
Training Loss 0.8571392410371933
Training Loss 0.8155247745835716
Training Loss 0.6958339231898802
Training Loss 0.7039694022157724
Training Loss 0.4574053718507752
Training Loss 0.4674782993763223
Training Loss 0.5864677752087741
Training Loss 0.5854298413579444
Training Loss 0.47123555058611705
Training Loss 0.6888302584457193
Training Loss 0.3620871944006309
Training Loss 0.7724855128381567
Training Loss 0.715952576575548
Training Loss 0.5166070900663988
Training Loss 0.5280158637605159
Training Loss 0.40710221202155605
Training Loss 0.46951962132262753
Training Loss 0.4710348303640283
Training Loss 0.5499369303385416
Training Loss 0.7904196327526104
Training Loss 0.5942840866079203
Training Loss 0.7472403097472735
Training Loss 0.6023010093708989
Training Loss 0.49545538359754865
Training Loss 0.7246220663047196
Training Loss 0.5904748715112484
Loss and Error 0.6376496376302796 19.241138110677984
saving as ./model10//035_19.2411.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5185743598264446
Training Loss 0.3946998946122736
Training Loss 0.8796638150205833
Training Loss 0.7924328616711155
Training Loss 0.5342578317778836
Training Loss 0.6388392493943448
Training Loss 0.49208873335577497
Training Loss 0.3573846210457309
Training Loss 0.5332664387556997
Training Loss 0.548476573088913
Training Loss 0.5861748241631054
Training Loss 0.5190020880598654
Training Loss 0.40729271294870834
Training Loss 0.6902982327594234
Training Loss 0.5584855586924451
Training Loss 0.7226174231803063
Training Loss 0.45053954840557087
Training Loss 0.4063288209346148
Training Loss 0.7761833639705882
Training Loss 0.3670048007874406
Training Loss 0.3541585704802313
Training Loss 0.8143884680557586
Training Loss 0.5654179423951305
Training Loss 0.3836706609673839
Training Loss 0.406531130488498
Training Loss 0.4418105958726136
Training Loss 0.628706255881042
Training Loss 0.4347442155031814
Training Loss 0.46859445701357466
Training Loss 0.5581167479227006
Training Loss 0.5564048288829291
Training Loss 0.4577198078364679
Training Loss 0.7234092987145083
Training Loss 0.43721809216654245
Training Loss 0.33047336180177783
Training Loss 0.43293134453233656
Training Loss 0.07016020545360561
Training Loss 0.6486072344598672
Training Loss 0.5036672036782722
Training Loss 0.38974717818527177
Training Loss 0.2141221949767084
Training Loss 0.5110630603386018
Training Loss 0.36973294123011274
Training Loss 0.8133852622980984
Training Loss 0.3915537115835883
Training Loss 0.232659773602969
Training Loss 0.8025620653450144
Training Loss 0.5565766481675318
Training Loss 0.8285910098497955
Training Loss 0.5672257728702558
Training Loss 0.7918316147233423
Training Loss 0.46652978186261596
Training Loss 0.5743617436776045
Training Loss 0.3740825514527845
Training Loss 0.739583916620377
Training Loss 0.6154174252998833
Training Loss 0.7025437406437126
Training Loss 0.422058934698361
Training Loss 0.358459184664006
Training Loss 0.4931944161813574
Training Loss 0.6088761238243444
Training Loss 0.7406030090914217
Training Loss 0.6003874083909749
Training Loss 0.5112377908152014
Training Loss 0.7267031598677982
Training Loss 0.45238232879039564
Training Loss 0.7691995388354206
Training Loss 0.6677406100499959
Training Loss 0.34483908295826515
Training Loss 0.4519953878818156
Training Loss 0.042693575331364274
Training Loss 0.431820607403967
Training Loss 0.5369424639595273
Training Loss 0.5053879587273848
Training Loss 0.5159970961920298
Training Loss 0.6090128277524217
Training Loss 0.47794515078829736
Training Loss 0.5447453862791074
Loss and Error 0.7155910585658385 17.23104666836679
saving as ./model10//036_17.2310.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5344999421317622
Training Loss 0.5444791485654155
Training Loss 0.6861252548842944
Training Loss 0.8358648955542531
Training Loss 0.5641948432232609
Training Loss 0.7296301973527611
Training Loss 0.5501700680272109
Training Loss 0.5330160336389662
Training Loss 0.5658036936884341
Training Loss 0.7616539053907754
Training Loss 0.7022959568273489
Training Loss 0.4871111467953171
Training Loss 0.5964947183623569
Training Loss 0.5516205845718429
Training Loss 0.3863768423408253
Training Loss 0.7160248973571626
Training Loss 0.5326567150297619
Training Loss 0.4047445991595468
Training Loss 0.33585949197252346
Training Loss 0.09051723221976245
Training Loss 0.5441547564999281
Training Loss 0.5360498091822645
Training Loss 0.452768838342653
Training Loss 0.5048732078934047
Training Loss 0.7364504567050322
Training Loss 0.3646759746406058
Training Loss 0.5375989586149258
Training Loss 0.6152671855064502
Training Loss 0.5228899303911511
Training Loss 0.48856909905614243
Training Loss 0.6388292508261701
Training Loss 0.7373826244255179
Training Loss 0.3015783843167238
Training Loss 0.6140929979526728
Training Loss 0.7529626002712373
Training Loss 0.3522425589801596
Training Loss 0.46661134229862117
Training Loss 0.46778696545456194
Training Loss 0.49503686834350363
Training Loss 0.6094031410335254
Training Loss 0.42393273370550427
Training Loss 0.5656841035379282
Training Loss 0.650073007231518
Training Loss 0.443595946402468
Training Loss 0.29305214497428067
Training Loss 0.5829281474799141
Training Loss 0.4756976645246303
Training Loss 0.47172324449085273
Training Loss 0.6185918913131352
Training Loss 0.8460683218902177
Training Loss 0.12737363630651496
Training Loss 0.5025126078591418
Training Loss 0.6329981570379893
Training Loss 0.6707259644853308
Training Loss 0.5383277319862041
Training Loss 0.53725896570837
Training Loss 0.556325736213371
Training Loss 0.7143762749320036
Training Loss 0.3388718370716906
Training Loss 0.4466117545470052
Training Loss 0.7173755485427785
Training Loss 0.48090397541682917
Training Loss 0.07467486034935807
Training Loss 0.6340004769115796
Training Loss 0.525600284837667
Training Loss 0.6997211162860577
Training Loss 0.5915363576727521
Training Loss 0.602519139913479
Training Loss 0.5720797955861419
Training Loss 0.629960787879346
Training Loss 0.6841126936226626
Training Loss 0.9057598267511178
Training Loss 0.3076222035973731
Training Loss 0.5923365604579257
Training Loss 0.5076352546274926
Training Loss 0.4759790311403607
Training Loss 0.7848149540148568
Training Loss 0.6418045862893276
Loss and Error 0.6976576438706341 18.11814638056031
saving as ./model10//037_18.1181.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5957209872463561
Training Loss 0.36867308571625235
Training Loss 0.4929038735813944
Training Loss 0.47012381668640385
Training Loss 0.7017663266478467
Training Loss 0.4211355713985426
Training Loss 0.8120433174250349
Training Loss 0.7289084592378421
Training Loss 0.43980753716816473
Training Loss 0.6733024667162414
Training Loss 0.6580922015716629
Training Loss 0.3689671708842307
Training Loss 0.40404533617424243
Training Loss 0.4096289479834402
Training Loss 0.8339640705105383
Training Loss 0.5286356140155436
Training Loss 0.25804208947472945
Training Loss 0.8456945954164112
Training Loss 0.44647746045196435
Training Loss 0.7237874795669196
Training Loss 0.8133879294428032
Training Loss 0.38591094301038403
Training Loss 0.8457085407192768
Training Loss 0.3817704003551995
Training Loss 0.4954181444429304
Training Loss 0.6133304092494783
Training Loss 0.4971189138188454
Training Loss 0.6505058202636108
Training Loss 0.7331017066264243
Training Loss 0.5557987898725518
Training Loss 0.41948589960187377
Training Loss 0.5028730840581649
Training Loss 0.3619479503152865
Training Loss 0.5710508334348038
Training Loss 0.7258089332231008
Training Loss 0.47471529684706754
Training Loss 0.48189915953119844
Training Loss 0.5548235527733887
Training Loss 0.48145432393703863
Training Loss 0.3592204476253784
Training Loss 0.3177685402602799
Training Loss 0.3399731838511164
Training Loss 0.38662240567275397
Training Loss 0.2918670277309619
Training Loss 0.49105025203246544
Training Loss 0.4005071893908141
Training Loss 0.6040914969880663
Training Loss 0.5659882392649009
Training Loss 0.6708648527831308
Training Loss 0.578474329671174
Training Loss 0.5931464041095891
Training Loss 0.7958854870149804
Training Loss 0.4637765600851855
Training Loss 0.8487356239689562
Training Loss 0.12449096149715087
Training Loss 0.4458738802465176
Training Loss 0.40085728236607143
Training Loss 0.6726967149954596
Training Loss 0.6758872793860671
Training Loss 0.35397390944965873
Training Loss 0.4500686044516818
Training Loss 0.6447923428227003
Training Loss 0.7375321581946845
Training Loss 0.4849196631973428
Training Loss 0.7039743009546983
Training Loss 0.5022190999711569
Training Loss 0.6042208679434098
Training Loss 0.6441818032253769
Training Loss 0.3979961221148859
Training Loss 0.6065594896616917
Training Loss 0.6657572053301812
Training Loss 0.7826564216004392
Training Loss 0.8517102573614991
Training Loss 0.41870728266537544
Training Loss 0.4966315107862617
Training Loss 0.6857368718409798
Training Loss 0.5931586027145386
Training Loss 0.3668533349531499
Loss and Error 0.5191046210611427 19.195599111078728
saving as ./model10//038_19.1956.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6194554822198276
Training Loss 0.7385326583172547
Training Loss 0.7145615519438384
Training Loss 0.45463873496043283
Training Loss 0.6289742493782914
Training Loss 0.4825996251509542
Training Loss 0.48547342509217245
Training Loss 0.5448244861966941
Training Loss 0.6383437880235467
Training Loss 0.504239588077592
Training Loss 0.49691351459364685
Training Loss 0.5199966109471478
Training Loss 0.6532529362416107
Training Loss 0.7262213172254314
Training Loss 0.5309493315345641
Training Loss 0.39235821207061067
Training Loss 0.6216766541970176
Training Loss 0.505152335579195
Training Loss 0.3070408025995148
Training Loss 0.6195198980067064
Training Loss 0.967907711265025
Training Loss 0.649800605797723
Training Loss 0.4899217772040415
Training Loss 0.6554437681686046
Training Loss 0.8015541497606712
Training Loss 0.5665719521755219
Training Loss 0.5085029753659049
Training Loss 0.5023128087636998
Training Loss 0.42739660729895107
Training Loss 0.4722851013869382
Training Loss 0.5463394966194554
Training Loss 0.4575224998512123
Training Loss 0.3558589895975958
Training Loss 0.4984658839374316
Training Loss 0.6207923448081847
Training Loss 0.36881482208622185
Training Loss 0.48730480084290856
Training Loss 0.5986563299364884
Training Loss 0.6150541149930798
Training Loss 0.4939890085800288
Training Loss 0.38721036669234155
Training Loss 0.3981809511289492
Training Loss 0.3806328567899633
Training Loss 0.33616543116248426
Training Loss 0.4128824498192542
Training Loss 0.5546226385123687
Training Loss 0.791074234785509
Training Loss 0.5492355193279679
Training Loss 0.6395495716875815
Training Loss 0.8647896818602965
Training Loss 0.3322381755055591
Training Loss 0.5071546623117071
Training Loss 0.4915772340408047
Training Loss 0.5510178743229761
Training Loss 0.3212545178406644
Training Loss 0.649539392415804
Training Loss 0.7262945832096199
Training Loss 0.6818603892967543
Training Loss 0.31280251582744406
Training Loss 0.6583089054070841
Training Loss 0.6667862901655939
Training Loss 0.5035332849376758
Training Loss 0.4791489886147963
Training Loss 0.9815116090178325
Training Loss 0.35864482108620754
Training Loss 0.500117506259273
Training Loss 0.3647480445506418
Training Loss 0.7281995871791174
Training Loss 0.38260290695466515
Training Loss 0.37179981221883035
Training Loss 0.26439217600181464
Training Loss 0.4899157519369478
Training Loss 0.5816944753504472
Training Loss 0.5416644257955184
Training Loss 0.6236515345402064
Training Loss 0.32237257874916775
Training Loss 0.5280051952364536
Training Loss 0.6040454117344053
Loss and Error 0.6458445913010573 18.58264417647273
saving as ./model10//039_18.5826.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5150021250253105
Training Loss 0.6519163855883066
Training Loss 0.6926008678354763
Training Loss 0.4183720078579215
Training Loss 0.4207029392874122
Training Loss 0.730427506689326
Training Loss 0.35221562896100506
Training Loss 0.3720715218212777
Training Loss 0.5502455359370011
Training Loss 0.6075537936495119
Training Loss 0.42899781773072787
Training Loss 0.4565299366067198
Training Loss 0.4347607900444112
Training Loss 0.37696567463249314
Training Loss 0.7340290932023844
Training Loss 0.6762413938957385
Training Loss 0.38036707026525174
Training Loss 0.7603685197787048
Training Loss 0.4680523642674478
Training Loss 0.683465855722209
Training Loss 0.7054843046271805
Training Loss 0.7415271412242542
Training Loss 0.3646360250359832
Training Loss 0.7256232264041238
Training Loss 0.5846808255033926
Training Loss 0.40056208953757755
Training Loss 0.5326305599083896
Training Loss 0.9807591142017146
Training Loss 0.7733159192743149
Training Loss 0.5595243989219961
Training Loss 0.6330169201879229
Training Loss 0.29151826968084077
Training Loss 0.4877748714188086
Training Loss 0.573316076550123
Training Loss 0.8465698703902386
Training Loss 0.34475630381119754
Training Loss 0.5349078640370549
Training Loss 0.3745662390075892
Training Loss 0.8461120741577732
Training Loss 0.5659692504062591
Training Loss 0.3501193594867592
Training Loss 0.6908994908838647
Training Loss 0.49058190404298446
Training Loss 0.6861968036019583
Training Loss 0.5493558902877698
Training Loss 0.4506303721380423
Training Loss 0.4144751572027439
Training Loss 0.5494962840723411
Training Loss 0.5355390151254135
Training Loss 0.6365845011440708
Training Loss 0.7150594114533397
Training Loss 0.5023845187561349
Training Loss 0.6018342016833447
Training Loss 0.47848752552956914
Training Loss 0.45918654916875784
Training Loss 0.35336230675836866
Training Loss 0.4103013319164741
Training Loss 0.6883332625679348
Training Loss 0.5364403251237021
Training Loss 0.5299493605090726
Training Loss 0.5056830080610683
Training Loss 0.6063732806831923
Training Loss 0.5318575402462121
Training Loss 0.6737694048436559
Training Loss 0.43096173607922433
Training Loss 0.7155350990367173
Training Loss 0.657299461013637
Training Loss 0.4992449473366361
Training Loss 0.4718133572539593
Training Loss 0.5225590921602321
Training Loss 0.2630976595410052
Training Loss 0.34291618421722314
Training Loss 0.3373433655495079
Training Loss 0.7275224487811204
Training Loss 0.45851766652074355
Training Loss 0.4238660823664016
Training Loss 0.6229507209456416
Training Loss 0.7064148023561205
Loss and Error 0.561482573901072 19.501621188385734
saving as ./model10//040_19.5016.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6022530911663386
Training Loss 0.6119697091729147
Training Loss 0.6542833238401965
Training Loss 0.7017995013395478
Training Loss 0.21900225799095813
Training Loss 0.5608366522685112
Training Loss 0.7435202738601236
Training Loss 0.2588010845762311
Training Loss 0.37989822667387985
Training Loss 0.4018593291626789
Training Loss 0.3810382230340526
Training Loss 0.5340900127704327
Training Loss 0.6205279555794113
Training Loss 0.7320303528953412
Training Loss 0.41259757734223496
Training Loss 0.4442965400182705
Training Loss 0.5340931789260681
Training Loss 0.34709425982306985
Training Loss 0.5577299579146671
Training Loss 0.26415158512340675
Training Loss 0.6065321565828761
Training Loss 0.5240690536405869
Training Loss 0.5842584786918233
Training Loss 0.41523029622591107
Training Loss 0.6514595578668084
Training Loss 0.5571765973213624
Training Loss 0.3447905155124427
Training Loss 0.7137830760380993
Training Loss 0.9540378736413043
Training Loss 0.31622310780732926
Training Loss 0.507947296575271
Training Loss 0.8938341370622964
Training Loss 0.501771734804962
Training Loss 0.33806961595215906
Training Loss 0.5842002632323934
Training Loss 0.6334905504604469
Training Loss 0.6104802242411388
Training Loss 0.49779534180281876
Training Loss 0.923889719800639
Training Loss 0.48940029015806796
Training Loss 0.550403596041345
Training Loss 0.44108362067235657
Training Loss 0.43882302031403236
Training Loss 0.8467428511549926
Training Loss 0.37619218165270096
Training Loss 0.558109200980061
Training Loss 0.24386641194793354
Training Loss 0.562472124516874
Training Loss 0.2959788921729412
Training Loss 0.3338996194047212
Training Loss 0.6005792829003407
Training Loss 0.4102035537194239
Training Loss 0.35944184303611304
Training Loss 0.40825166882732894
Training Loss 0.5318461106946271
Training Loss 0.9306809963390906
Training Loss 0.38364270918766774
Training Loss 0.48489262258156296
Training Loss 0.49750685918898807
Training Loss 0.7170544565158025
Training Loss 0.6818133993881597
Training Loss 0.5679259600735731
Training Loss 0.6360662385386961
Training Loss 0.6520280319493467
Training Loss 0.6708449823037594
Training Loss 0.3555323367011278
Training Loss 0.6519581024851278
Training Loss 0.42266380582960733
Training Loss 0.5643678404938156
Training Loss 0.7334072971539362
Training Loss 0.47090643840169544
Training Loss 0.518004314609114
Training Loss 0.72963228451353
Training Loss 0.44861710428565915
Training Loss 0.7223788302638688
Training Loss 0.3909698121576195
Training Loss 0.35758421509236504
Training Loss 0.40841625442287105
Loss and Error 0.6085037697724496 17.246529928230537
saving as ./model10//041_17.2465.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.4827231811710375
Training Loss 0.712116360425608
Training Loss 0.5375247274285297
Training Loss 0.34646120730105107
Training Loss 0.4423837699142157
Training Loss 0.5151385412737254
Training Loss 0.5640852874670746
Training Loss 0.7212569849234008
Training Loss 0.4885798328763237
Training Loss 0.7305895077284946
Training Loss 0.4126510131338272
Training Loss 0.6045399227978319
Training Loss 0.32560991905925474
Training Loss 0.6042077223350034
Training Loss 0.31744637678616705
Training Loss 0.32559851902647585
Training Loss 0.6625354130123707
Training Loss 0.48561457181047196
Training Loss 0.4178908546184016
Training Loss 0.3731759737338838
Training Loss 0.5750184429400149
Training Loss 0.7082619617172038
Training Loss 0.5603038623709573
Training Loss 0.34562746433372465
Training Loss 0.6037067544051792
Training Loss 0.7764213558019362
Training Loss 0.36752491332143133
Training Loss 0.600750661402186
Training Loss 0.7557269054150764
Training Loss 0.4708795162222265
Training Loss 0.2801233076045637
Training Loss 0.463539641895933
Training Loss 0.6806664050787107
Training Loss 0.5197131797206976
Training Loss 0.48020348182091344
Training Loss 0.39274492392475635
Training Loss 0.5966077009743936
Training Loss 0.4702223407251335
Training Loss 0.43755900244989687
Training Loss 0.36388197370200787
Training Loss 0.8244728822678521
Training Loss 0.45515696992115207
Training Loss 0.523917574842437
Training Loss 0.688889475089581
Training Loss 0.21911105303697184
Training Loss 0.8875008210312897
Training Loss 0.7370895047955384
Training Loss 0.56457939827705
Training Loss 0.33834899524478657
Training Loss 0.4412261018680677
Training Loss 0.6073222288418494
Training Loss 0.8993863348070317
Training Loss 0.685106867296399
Training Loss 0.05424676308748046
Training Loss 0.503225158865737
Training Loss 0.29631966842590274
Training Loss 0.5002316909645854
Training Loss 0.7971634467036942
Training Loss 0.441663646786767
Training Loss 0.4173767146028306
Training Loss 0.6707801617485337
Training Loss 0.7948895075955509
Training Loss 0.765069838356069
Training Loss 0.4457514148622047
Training Loss 0.4968618997713415
Training Loss 0.43189135637059045
Training Loss 0.42474480862546515
Training Loss 0.39004362367351647
Training Loss 0.6117576614419221
Training Loss 0.3264868003795131
Training Loss 0.545101670384236
Training Loss 0.5218308402863846
Training Loss 0.5915439940818668
Training Loss 0.6311665942308505
Training Loss 0.5802035656039563
Training Loss 0.5765103909038447
Training Loss 0.4864319097653964
Training Loss 0.5459435902354087
Loss and Error 0.6311382462263404 17.864038762796458
saving as ./model10//042_17.8640.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.18418346463487326
Training Loss 0.4448800223214286
Training Loss 0.5008492503061259
Training Loss 0.5036496500020188
Training Loss 0.39155421359622733
Training Loss 0.23937279605575607
Training Loss 0.37433601792643334
Training Loss 0.5590443086565204
Training Loss 0.7503626848349381
Training Loss 0.24382695422008988
Training Loss 0.36549612192007214
Training Loss 0.4632653453716005
Training Loss 0.27478883063709614
Training Loss 0.5299737238608903
Training Loss 0.5327672829581993
Training Loss 0.48893824986049106
Training Loss 0.8288446549536226
Training Loss 0.6627039977279314
Training Loss 0.4635343240914787
Training Loss 0.6812777555575407
Training Loss 0.35115454500558896
Training Loss 0.6575750529414051
Training Loss 0.5735745230987466
Training Loss 0.5903825871871033
Training Loss 0.2759484458308649
Training Loss 0.9777100584637151
Training Loss 0.8283529263519924
Training Loss 0.8110731636200261
Training Loss 0.5248883756920948
Training Loss 0.31035810324144714
Training Loss 0.5760950803018576
Training Loss 0.46200263177267376
Training Loss 0.3339515856418657
Training Loss 0.5579514387771393
Training Loss 0.34616376621131334
Training Loss 0.6661990177380765
Training Loss 0.5584991597331711
Training Loss 0.2369008321248129
Training Loss 0.4893574989951017
Training Loss 0.6510945774564807
Training Loss 0.716478079803719
Training Loss 0.723100937006189
Training Loss 0.49144555632190356
Training Loss 0.56890566129211
Training Loss 0.3702649628924693
Training Loss 0.5900854162267737
Training Loss 0.47627410545997756
Training Loss 0.5289237621278019
Training Loss 0.6182268011124276
Training Loss 0.5622458792518303
Training Loss 0.6511640702220418
Training Loss 0.6851806255909234
Training Loss 0.43819595008099155
Training Loss 0.49379898690335633
Training Loss 0.7118202831612125
Training Loss 0.4881547860349805
Training Loss 0.35733624956426346
Training Loss 0.8099138358454215
Training Loss 0.8413310630553792
Training Loss 0.52673223744268
Training Loss 0.5909194555038061
Training Loss 0.5044174896188245
Training Loss 0.8306831309519346
Training Loss 0.673381246867575
Training Loss 0.5716526258395292
Training Loss 0.4505394253876649
Training Loss 0.3572585440478632
Training Loss 0.6095540135127858
Training Loss 0.6144593003216912
Training Loss 0.4299021665393484
Training Loss 0.42363677684133844
Training Loss 0.6276328524106003
Training Loss 0.4631040148033858
Training Loss 0.7373529790521978
Training Loss 0.589817363304543
Training Loss 0.8238068292445483
Training Loss 0.3401004831855583
Training Loss 0.7525466465022526
Loss and Error 0.6608404656353202 18.22379685963059
saving as ./model10//043_18.2238.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.7859263879516196
Training Loss 0.41043163481212797
Training Loss 0.6425680214870251
Training Loss 0.32365879956157073
Training Loss 0.2988627384064653
Training Loss 0.695679182531575
Training Loss 0.5635889642151204
Training Loss 0.42945730524955034
Training Loss 0.6071850368268263
Training Loss 0.6472785093634402
Training Loss 0.437773446313741
Training Loss 0.6293852204666707
Training Loss 0.6236271087067294
Training Loss 0.6406252042448062
Training Loss 0.5864774452376815
Training Loss 0.5656907638058781
Training Loss 0.4854290049563172
Training Loss 0.5695627413637412
Training Loss 0.5967776763855379
Training Loss 0.5649857954545454
Training Loss 0.37048010648175367
Training Loss 0.6026699037140744
Training Loss 0.44761824584359605
Training Loss 0.1758097293501258
Training Loss 0.0950033998474446
Training Loss 0.7014503934218377
Training Loss 0.44780674206977394
Training Loss 0.4327991084710271
Training Loss 0.5020884894325545
Training Loss 0.38649978080805203
Training Loss 0.5148602441375818
Training Loss 0.7568140105571644
Training Loss 0.5149254754269339
Training Loss 0.64491848357885
Training Loss 0.7197102332370318
Training Loss 0.7556015812913409
Training Loss 0.7837363366291727
Training Loss 0.5547177218466708
Training Loss 0.6199228016063325
Training Loss 0.4328352517949339
Training Loss 0.7076331735453786
Training Loss 0.45156170144106444
Training Loss 0.4993149728486032
Training Loss 0.6062340741789355
Training Loss 0.7069256698243054
Training Loss 0.4804981944738973
Training Loss 0.22650159151024682
Training Loss 0.5432796199701937
Training Loss 0.4107687942036455
Training Loss 0.07696845164506931
Training Loss 0.8093924302672427
Training Loss 0.568859221509618
Training Loss 0.4302365871496677
Training Loss 0.38737750083320266
Training Loss 0.5052748794711049
Training Loss 0.6139711805316882
Training Loss 0.47017283028595674
Training Loss 0.5483107137578197
Training Loss 0.6532271290553435
Training Loss 0.6935591548204575
Training Loss 0.7170522953003876
Training Loss 0.554195214141187
Training Loss 0.3894520586213857
Training Loss 0.47423107369271283
Training Loss 0.5652911416609754
Training Loss 0.5477110077773614
Training Loss 0.47933298227738363
Training Loss 0.470525539404376
Training Loss 0.36664054068141677
Training Loss 0.588557994844751
Training Loss 0.32583039578008827
Training Loss 0.43139326707592707
Training Loss 0.4316800527431274
Training Loss 0.36927019515571935
Training Loss 0.3873380608514908
Training Loss 0.9317848930434169
Training Loss 0.7224601814940256
Training Loss 0.47809672130660197
Loss and Error 0.6201573078551352 19.71018980655033
saving as ./model10//044_19.7102.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.5633293751405969
Training Loss 0.525176234586557
Training Loss 0.742375191925578
Training Loss 0.2647002422069886
Training Loss 0.3678374785918731
Training Loss 0.27597935432891363
Training Loss 0.38690534167512325
Training Loss 0.783915364769558
Training Loss 0.5221026681777938
Training Loss 0.5304915004245435
Training Loss 0.576752431622837
Training Loss 0.5439774712548928
Training Loss 0.5911674634624963
Training Loss 0.5769789184306499
Training Loss 0.43563547674215064
Training Loss 0.1807207048145545
Training Loss 0.6843090143455834
Training Loss 0.3749130554509883
Training Loss 0.5152015530502514
Training Loss 0.23456363583710874
Training Loss 0.48709611376992534
Training Loss 0.5608237748066078
Training Loss 0.5533348424823763
Training Loss 0.486722046358089
Training Loss 0.28591206247615847
Training Loss 0.7225332412866352
Training Loss 0.6815429530091474
Training Loss 0.6146805307631676
Training Loss 0.35192405723057185
Training Loss 0.37427292934279816
Training Loss 0.41313839651336043
Training Loss 0.7272045982282236
Training Loss 0.4177153935539326
Training Loss 0.4912101721688871
Training Loss 0.7293633355034722
Training Loss 0.6240339072132136
Training Loss 0.4038264513397624
Training Loss 0.38079994134930756
Training Loss 0.7010165660884494
Training Loss 0.5374258070811903
Training Loss 0.4256081646934655
Training Loss 0.46271299838747143
Training Loss 0.3296817412012043
Training Loss 0.5284631884050432
Training Loss 0.7217964404281573
Training Loss 0.623081304029633
Training Loss 0.5358137190525123
Training Loss 0.6351447627145057
Training Loss 0.23930881131652904
Training Loss 0.497476793695364
Training Loss 0.3453395168410181
Training Loss 0.4930990850266024
Training Loss 0.5674640729611168
Training Loss 0.4822165428558526
Training Loss 0.6187204928289031
Training Loss 0.3495943449710925
Training Loss 0.5323671481753356
Training Loss 0.4116857460457822
Training Loss 0.5552559094551283
Training Loss 0.5327231552077567
Training Loss 0.3083145916053134
Training Loss 0.4163730899322566
Training Loss 0.35599227191076616
Training Loss 0.5489248649653963
Training Loss 0.44389606344288796
Training Loss 0.26251038810275246
Training Loss 0.592154453340815
Training Loss 0.7985091006311947
Training Loss 0.49418316092542425
Training Loss 0.48186863451035694
Training Loss 0.6922518906594638
Training Loss 0.505287298088688
Training Loss 0.4403402465147543
Training Loss 0.5683006451964009
Training Loss 0.6183171960969739
Training Loss 0.3841976641474473
Training Loss 0.8688859494913843
Training Loss 0.31148404505940164
Loss and Error 0.6059156077172905 19.18740209115086
saving as ./model10//045_19.1874.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.36110418818123435
Training Loss 0.469579877032966
Training Loss 0.8177856792212662
Training Loss 0.4102039281355142
Training Loss 0.6531019133467257
Training Loss 0.5347080629739801
Training Loss 0.33620089556494326
Training Loss 0.418361911525974
Training Loss 0.4760838971332356
Training Loss 0.2847946049487761
Training Loss 0.529696043841288
Training Loss 0.48176580212005987
Training Loss 0.48024923429306754
Training Loss 0.5260015405837458
Training Loss 0.5761808306593437
Training Loss 0.6109871548015543
Training Loss 0.7220389480548646
Training Loss 0.6406705059140938
Training Loss 0.5296723454262995
Training Loss 0.6514561124484182
Training Loss 0.6263606910541846
Training Loss 0.6405062391662122
Training Loss 0.37070248396473743
Training Loss 0.5278727090051214
Training Loss 0.46988618976502344
Training Loss 0.26453563937107827
Training Loss 0.3834483475124226
Training Loss 0.35719191251327903
Training Loss 0.5343579027902908
Training Loss 0.5468300224693505
Training Loss 0.4943350984772936
Training Loss 0.3596764632741097
Training Loss 0.7541078728329393
Training Loss 0.5392824230539487
Training Loss 0.4224319507453014
Training Loss 0.4811257407911844
Training Loss 0.3342011214754277
Training Loss 0.5623618267952127
Training Loss 0.7878794235080824
Training Loss 0.3358020597291224
Training Loss 0.2809606708342607
Training Loss 0.7223426968443627
Training Loss 0.37048160493428606
Training Loss 0.4528448323982209
Training Loss 0.5220452529756501
Training Loss 0.2971197409707992
Training Loss 0.37994872613232683
Training Loss 0.6182577315839838
Training Loss 0.6938323556814725
Training Loss 0.057462628423925265
Training Loss 0.7841544196047768
Training Loss 0.5780094877995269
Training Loss 0.581335390625
Training Loss 0.3733545719957281
Training Loss 0.630180609111234
Training Loss 0.37322658524013586
Training Loss 0.7512754290291432
Training Loss 0.22119475122214274
Training Loss 0.5523812115778689
Training Loss 0.45017671981522284
Training Loss 0.5398367011980163
Training Loss 0.542822007916796
Training Loss 0.9615678965400688
Training Loss 0.6248744118110591
Training Loss 0.42151013449043045
Training Loss 0.665037131360283
Training Loss 0.6460750382830839
Training Loss 0.5553755647024334
Training Loss 0.39700512587080433
Training Loss 0.6030705458748222
Training Loss 0.6490250869850913
Training Loss 0.5375261910354034
Training Loss 0.584905116032014
Training Loss 0.4825841432472785
Training Loss 0.3874945484433709
Training Loss 0.6446500724028401
Training Loss 0.6610358662786633
Training Loss 0.2752222716321618
Loss and Error 0.6467026497219142 17.962403001930852
saving as ./model10//046_17.9624.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.3642622695841202
Training Loss 0.5976624238286737
Training Loss 0.5181384887505821
Training Loss 0.6424432111984858
Training Loss 0.4337543018461553
Training Loss 0.629016409372416
Training Loss 0.42342573658266763
Training Loss 0.4374406905925418
Training Loss 0.23219645477682624
Training Loss 0.4230678580160999
Training Loss 0.43741383479530843
Training Loss 0.5577914132134129
Training Loss 0.3391071175302572
Training Loss 0.4470246627720708
Training Loss 0.4705502666070709
Training Loss 0.39945405174778487
Training Loss 0.3120972434372585
Training Loss 0.619405433614418
Training Loss 0.07041599837665798
Training Loss 0.3960789632065378
Training Loss 0.26321511924813645
Training Loss 0.6913750738989063
Training Loss 0.41697151561977075
Training Loss 0.26864928801336374
Training Loss 0.6519898687090192
Training Loss 0.510017578125
Training Loss 0.6484899310813601
Training Loss 0.42647668521542864
Training Loss 0.49041559962707704
Training Loss 0.5407444830183229
Training Loss 0.3560315690428068
Training Loss 0.3579140628221915
Training Loss 0.8547753749540318
Training Loss 0.41981927920887646
Training Loss 0.5051817462649596
Training Loss 0.6421564147349798
Training Loss 0.41889846895370014
Training Loss 0.7176906829576297
Training Loss 0.5045317716949443
Training Loss 0.3483995009941878
Training Loss 0.5308205148448115
Training Loss 0.6218538851351352
Training Loss 0.5138270940474552
Training Loss 0.5510527197994403
Training Loss 0.39628782298277426
Training Loss 0.5224895919416218
Training Loss 0.4099394283289046
Training Loss 0.4617288762872869
Training Loss 0.7715615688738942
Training Loss 0.3684495061739571
Training Loss 0.815568358033568
Training Loss 0.41481764853965597
Training Loss 0.49224463164050986
Training Loss 0.6619332317163735
Training Loss 0.49138078194439544
Training Loss 0.3105440903906473
Training Loss 0.5584984626742396
Training Loss 0.3733524379708225
Training Loss 0.666962376966578
Training Loss 0.2491621775917907
Training Loss 0.5777424410484444
Training Loss 0.7161954309320401
Training Loss 0.8485503335949764
Training Loss 0.5518056288122494
Training Loss 0.6957602263289037
Training Loss 0.7351757876768674
Training Loss 0.6188904710591133
Training Loss 0.46822081200575477
Training Loss 0.3869548395753817
Training Loss 0.5693608826067902
Training Loss 0.7027351818680609
Training Loss 0.377582327120062
Training Loss 0.487017854445848
Training Loss 0.5506956766419492
Training Loss 0.509854026245915
Training Loss 0.4528948586168872
Training Loss 0.37093657198906543
Training Loss 0.4350454815284559
Loss and Error 0.6569795713152817 17.921417902291523
saving as ./model10//047_17.9214.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.490410522189584
Training Loss 0.40142462299405346
Training Loss 0.33623256001035856
Training Loss 0.7828743630501444
Training Loss 0.7786986070142506
Training Loss 0.5616903908079626
Training Loss 0.3196276896772147
Training Loss 0.3523433273046984
Training Loss 0.5136284615872655
Training Loss 0.5681500346791425
Training Loss 0.5535414378266998
Training Loss 0.34240602878819737
Training Loss 0.41658521054395986
Training Loss 0.4609542942101336
Training Loss 0.4081858782147001
Training Loss 0.187656663593493
Training Loss 0.4233812360448834
Training Loss 0.3805643471310059
Training Loss 0.4728265773060409
Training Loss 0.4197565161071843
Training Loss 0.4813071998162272
Training Loss 0.5231708152224593
Training Loss 0.4563914909203563
Training Loss 0.3178099260526941
Training Loss 0.5666016960926813
Training Loss 0.06027050510308095
Training Loss 0.33765445410588996
Training Loss 0.5429745560453978
Training Loss 0.6661755618751838
Training Loss 0.55589990234375
Training Loss 0.4454529634171516
Training Loss 0.7280294815838442
Training Loss 0.46320511643119816
Training Loss 0.388197093864507
Training Loss 0.26065140736253956
Training Loss 0.5197493306706461
Training Loss 0.815914357621266
Training Loss 0.11994173848909626
Training Loss 0.6336504641488312
Training Loss 0.6566148130416279
Training Loss 0.5077535411029308
Training Loss 0.3961085592620654
Training Loss 0.43274766868607734
Training Loss 0.3801123422350384
Training Loss 0.34990968095495345
Training Loss 0.4974162938510925
Training Loss 0.7492581763413823
Training Loss 0.45864303732366773
Training Loss 0.47640590434274727
Training Loss 0.8662473082686218
Training Loss 0.33949216638839563
Training Loss 0.38997181175541024
Training Loss 0.8287401133013305
Training Loss 0.6728500788134306
Training Loss 0.6915579617879037
Training Loss 0.5334274833446843
Training Loss 0.2672554152054353
Training Loss 0.48129691627175264
Training Loss 0.1999359647151838
Training Loss 0.4288361994507545
Training Loss 0.37992372770399446
Training Loss 0.5179030678488992
Training Loss 0.4733634341261808
Training Loss 0.6136039402173913
Training Loss 0.4532507487282541
Training Loss 0.4392471545091454
Training Loss 0.4088704524166791
Training Loss 0.4547790739875158
Training Loss 0.3368060105846774
Training Loss 0.5399769658627718
Training Loss 0.5885289698686181
Training Loss 0.6621140779922097
Training Loss 0.687292669432082
Training Loss 0.44204318476263843
Training Loss 0.45269973181638945
Training Loss 0.5445760591024262
Training Loss 0.4784501221607092
Training Loss 0.34824180442701036
Loss and Error 0.6215981059460369 18.946956173266784
saving as ./model10//048_18.9470.w
20Th iteration onwards
teacher_force 0.01
Training Loss 0.6455357105783285
Training Loss 0.40269954524350515
Training Loss 0.5507315219603988
Training Loss 0.29370039827373456
Training Loss 0.431251630515802
Training Loss 0.5623122864387474
Training Loss 0.4472351747047244
Training Loss 0.4538900416517741
Training Loss 0.45266623590225563
Training Loss 0.43230436941492173
Training Loss 0.2879188351514863
Training Loss 0.38782791071063044
Training Loss 0.49314786845350544
Training Loss 0.49261085579723485
Training Loss 0.2791760073506773
Training Loss 0.6365742809081303
Training Loss 0.5386804021876892
Training Loss 0.5175479432139968
Training Loss 0.3830143332670906
Training Loss 0.5890204255791343
Training Loss 0.48007761200845295
Training Loss 0.6480205228543394
Training Loss 0.6316927578782788
Training Loss 0.9664030868274773
Training Loss 0.3754384145314321
Training Loss 0.4835593466722328
Training Loss 0.32764020444074154
Training Loss 0.4387958233173077
Training Loss 0.7785478853233034
Training Loss 0.6840233590837396
Training Loss 0.42096050970709764
Training Loss 0.5154329380756839
Training Loss 0.6129626304379409
Training Loss 0.506098406611921
Training Loss 0.6708768956801471
Training Loss 0.7898693769904459
Training Loss 0.30043683488472067
Training Loss 0.5678017929922031
Training Loss 0.5926967545963961
Training Loss 0.5362210699090375
Training Loss 0.5607610633588294
Training Loss 0.2200220219222954
Training Loss 0.15016452888108023
Training Loss 0.41578693971145536
Training Loss 0.4475448626716311
Training Loss 0.6710886617919455
Training Loss 0.30092410621791116
Training Loss 0.5714214077152905
Training Loss 0.3719930609649927
Training Loss 0.5613134146743988
Training Loss 0.44765903493223125
Training Loss 0.44584571489741026
Training Loss 0.5459266263575308
Training Loss 0.47249613179788963
Training Loss 0.6281085156726082
Training Loss 0.37538243006993005
Training Loss 0.5204672964339179
Training Loss 0.5266470028844813
Training Loss 0.5500807131574453
Training Loss 0.37364412800649577
Training Loss 0.3425605548796107
Training Loss 0.2499042461444805
Training Loss 0.48291113411632175
Training Loss 0.5573957746809309
Training Loss 0.3986617091177941
Training Loss 0.524037545717769
Training Loss 0.5995347064260208
Training Loss 0.8544151600057704
Training Loss 0.5615084611124067
Training Loss 0.4112452103817235
Training Loss 0.5197556680463299
Training Loss 0.8073166116277555
Training Loss 0.2792231699866706
Training Loss 0.4179422036424751
Training Loss 0.4694333373948039
Training Loss 0.5674393011778293
Training Loss 0.761547364498909
Training Loss 0.39262005234593156
Loss and Error 0.6269962888937228 18.089912200808772
saving as ./model10//049_18.0899.w
20Th iteration onwards
